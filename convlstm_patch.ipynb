{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pylab as plt\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, BatchNormalization, concatenate, Input, ConvLSTM2D, Reshape, Conv3D, Flatten, LSTM, GRU, Dense,Dropout, Add\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and standard deviation for train data \n",
    "mu = 13.262550318358528\n",
    "std = 36.12859290913875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, rIdx, cIdx, batch_size=32, dim=(120,120), n_channels=1, n_timesteps = 4, shuffle=True, augment_data = True,\n",
    "                standardize = False):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_timesteps = n_timesteps \n",
    "        self.shuffle = shuffle\n",
    "        self.augment_data = augment_data  \n",
    "        self.standardize = standardize \n",
    "        self.rIdx = rIdx \n",
    "        self.cIdx = cIdx \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' \n",
    "        \n",
    "        if self.augment_data == True:  # only augment data when training \n",
    "            # Initialization\n",
    "            X = np.empty((self.batch_size*6, 120, 120, 4))\n",
    "            y = np.empty((self.batch_size*6, 120, 120, 1)) \n",
    "\n",
    "            # Generate data\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                data = np.load('./storage/precipitation/train/' + ID)\n",
    "                # Store sample\n",
    "                x_data = data[:,:,:4] \n",
    "                y_data = data[:,:,-1].reshape((120,120,1)) \n",
    "                \n",
    "                X[i,] = x_data\n",
    "                y[i] = y_data \n",
    "                \n",
    "                # add 90 degrees rotation \n",
    "                X[i+self.batch_size,] = np.rot90(x_data)\n",
    "                y[i+self.batch_size] = np.rot90(y_data)  \n",
    "                \n",
    "                # add 180 degrees rotation \n",
    "                X[i+self.batch_size*2,] = np.rot90(np.rot90(x_data)) \n",
    "                y[i+self.batch_size*2] = np.rot90(np.rot90(y_data)) \n",
    "                \n",
    "                # add 270 degrees rotation \n",
    "                X[i+self.batch_size*3,] = np.rot90(np.rot90(np.rot90(x_data)))\n",
    "                y[i+self.batch_size*3] = np.rot90(np.rot90(np.rot90(y_data)))  \n",
    "                \n",
    "                # add horizontal flip \n",
    "                X[i+self.batch_size*4,] = np.fliplr(x_data)\n",
    "                y[i+self.batch_size*4] = np.fliplr(y_data) \n",
    "                \n",
    "                # add vertical filp \n",
    "                X[i+self.batch_size*5,] = np.flipud(x_data) \n",
    "                y[i+self.batch_size*5] = np.flipud(y_data)\n",
    "            \n",
    "            # shuffle once more to make training harder \n",
    "            X,y = shuffle(X,y) \n",
    "            return (X, y)\n",
    "        \n",
    "        else: \n",
    "            # Initialization\n",
    "            size = 12 \n",
    "            X = np.empty((self.batch_size, 4, size, size, 1))\n",
    "            y = np.empty((self.batch_size, size, size, 1)) \n",
    "\n",
    "            # Generate data\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                data = np.load('./storage/precipitation/train/' + ID).astype(np.float32) \n",
    "                if self.standardize:  \n",
    "                    data = (data - mu)/std\n",
    "                # Store sample\n",
    "                X[i,] = data[size*self.rIdx:size*(1+self.rIdx),size*self.cIdx:size*(1+self.cIdx),:4].reshape((4,size,size,1))\n",
    "                y[i] = data[size*self.rIdx:size*(1+self.rIdx),size*self.cIdx:size*(1+self.cIdx),-1].reshape((size,size,1))   \n",
    "            \n",
    "            return (X, y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rnn(): \n",
    "    inputs = Input((4,12,12,1)) \n",
    "    conv = ConvLSTM2D(32, 3, padding = 'same', return_sequences = True)(inputs)\n",
    "    bn = BatchNormalization()(conv) \n",
    "    conv = ConvLSTM2D(32, 3, padding = 'same', return_sequences = False)(bn)\n",
    "    bn = BatchNormalization()(conv)  \n",
    "    outputs = Conv2D(1, 1, padding = \"same\", activation = 'relu')(bn) \n",
    "    model = Model(inputs=inputs,outputs=outputs) \n",
    "    model.compile(loss='mae',optimizer='adam')\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 4, 12, 12, 1)]    0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_14 (ConvLSTM2D) (None, 4, 12, 12, 32)     38144     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4, 12, 12, 32)     128       \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_15 (ConvLSTM2D) (None, 12, 12, 32)        73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 1)         33        \n",
      "=================================================================\n",
      "Total params: 112,289\n",
      "Trainable params: 112,161\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = simple_rnn() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........ Training model 1 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 0.00000, saving model to ./storage/precip_rnn/model1/epoch_001_val_loss_0.000.h5\n",
      "196/196 [==============================] - 107s 548ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00002: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 67s 340ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00003: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00004: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00005: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00006: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "........ Training model 2 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5055\n",
      "Epoch 00001: val_loss improved from inf to 4.86547, saving model to ./storage/precip_rnn/model2/epoch_001_val_loss_4.865.h5\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 3.5002 - val_loss: 4.8655\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.2782\n",
      "Epoch 00002: val_loss improved from 4.86547 to 3.02829, saving model to ./storage/precip_rnn/model2/epoch_002_val_loss_3.028.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 2.2780 - val_loss: 3.0283\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.0668\n",
      "Epoch 00003: val_loss improved from 3.02829 to 2.01263, saving model to ./storage/precip_rnn/model2/epoch_003_val_loss_2.013.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 2.0683 - val_loss: 2.0126\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.9852\n",
      "Epoch 00004: val_loss improved from 2.01263 to 1.91452, saving model to ./storage/precip_rnn/model2/epoch_004_val_loss_1.915.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 1.9842 - val_loss: 1.9145\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.9257\n",
      "Epoch 00005: val_loss did not improve from 1.91452\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 53s 273ms/step - loss: 1.9263 - val_loss: 2.1728\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.8686\n",
      "Epoch 00006: val_loss improved from 1.91452 to 1.87616, saving model to ./storage/precip_rnn/model2/epoch_006_val_loss_1.876.h5\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 1.8686 - val_loss: 1.8762\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.8379\n",
      "Epoch 00007: val_loss improved from 1.87616 to 1.87342, saving model to ./storage/precip_rnn/model2/epoch_007_val_loss_1.873.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 1.8405 - val_loss: 1.8734\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.8100\n",
      "Epoch 00008: val_loss improved from 1.87342 to 1.84118, saving model to ./storage/precip_rnn/model2/epoch_008_val_loss_1.841.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 1.8117 - val_loss: 1.8412\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.8010\n",
      "Epoch 00009: val_loss did not improve from 1.84118\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 1.8033 - val_loss: 1.8809\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.7609\n",
      "Epoch 00010: val_loss improved from 1.84118 to 1.82087, saving model to ./storage/precip_rnn/model2/epoch_010_val_loss_1.821.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 1.7598 - val_loss: 1.8209\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.7435\n",
      "Epoch 00011: val_loss improved from 1.82087 to 1.79274, saving model to ./storage/precip_rnn/model2/epoch_011_val_loss_1.793.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 1.7437 - val_loss: 1.7927\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.7356\n",
      "Epoch 00012: val_loss improved from 1.79274 to 1.77968, saving model to ./storage/precip_rnn/model2/epoch_012_val_loss_1.780.h5\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 1.7343 - val_loss: 1.7797\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.7235\n",
      "Epoch 00013: val_loss improved from 1.77968 to 1.77590, saving model to ./storage/precip_rnn/model2/epoch_013_val_loss_1.776.h5\n",
      "196/196 [==============================] - 57s 288ms/step - loss: 1.7265 - val_loss: 1.7759\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.7105\n",
      "Epoch 00014: val_loss improved from 1.77590 to 1.76669, saving model to ./storage/precip_rnn/model2/epoch_014_val_loss_1.767.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 1.7124 - val_loss: 1.7667\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.7009\n",
      "Epoch 00015: val_loss did not improve from 1.76669\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 1.7006 - val_loss: 1.7763\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6869\n",
      "Epoch 00016: val_loss did not improve from 1.76669\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 1.6910 - val_loss: 1.7793\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6747\n",
      "Epoch 00017: val_loss improved from 1.76669 to 1.76393, saving model to ./storage/precip_rnn/model2/epoch_017_val_loss_1.764.h5\n",
      "196/196 [==============================] - 54s 273ms/step - loss: 1.6758 - val_loss: 1.7639\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6773\n",
      "Epoch 00018: val_loss did not improve from 1.76393\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 1.6763 - val_loss: 1.7782\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6719\n",
      "Epoch 00019: val_loss improved from 1.76393 to 1.75943, saving model to ./storage/precip_rnn/model2/epoch_019_val_loss_1.759.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 1.6719 - val_loss: 1.7594\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6670\n",
      "Epoch 00020: val_loss improved from 1.75943 to 1.75880, saving model to ./storage/precip_rnn/model2/epoch_020_val_loss_1.759.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 1.6663 - val_loss: 1.7588\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6643\n",
      "Epoch 00021: val_loss did not improve from 1.75880\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 1.6639 - val_loss: 1.7625\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6632\n",
      "Epoch 00022: val_loss did not improve from 1.75880\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 1.6645 - val_loss: 1.7596\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6633\n",
      "Epoch 00023: val_loss did not improve from 1.75880\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 1.6627 - val_loss: 1.7598\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6586\n",
      "Epoch 00024: val_loss improved from 1.75880 to 1.75862, saving model to ./storage/precip_rnn/model2/epoch_024_val_loss_1.759.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 1.6586 - val_loss: 1.7586\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6584\n",
      "Epoch 00025: val_loss did not improve from 1.75862\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 64s 329ms/step - loss: 1.6589 - val_loss: 1.7593\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6592\n",
      "Epoch 00026: val_loss did not improve from 1.75862\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 63s 321ms/step - loss: 1.6595 - val_loss: 1.7591\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6574\n",
      "Epoch 00027: val_loss improved from 1.75862 to 1.75753, saving model to ./storage/precip_rnn/model2/epoch_027_val_loss_1.758.h5\n",
      "196/196 [==============================] - 64s 326ms/step - loss: 1.6585 - val_loss: 1.7575\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6615\n",
      "Epoch 00028: val_loss did not improve from 1.75753\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 65s 333ms/step - loss: 1.6628 - val_loss: 1.7586\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6599\n",
      "Epoch 00029: val_loss did not improve from 1.75753\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 61s 313ms/step - loss: 1.6606 - val_loss: 1.7588\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6587\n",
      "Epoch 00030: val_loss did not improve from 1.75753\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 1.6588 - val_loss: 1.7596\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6588\n",
      "Epoch 00031: val_loss did not improve from 1.75753\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 60s 306ms/step - loss: 1.6599 - val_loss: 1.7590\n",
      "Epoch 32/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.6595\n",
      "Epoch 00032: val_loss did not improve from 1.75753\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 1.6599 - val_loss: 1.7585\n",
      "........ Training model 3 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 10.0075\n",
      "Epoch 00001: val_loss improved from inf to 11.00997, saving model to ./storage/precip_rnn/model3/epoch_001_val_loss_11.010.h5\n",
      "196/196 [==============================] - 61s 311ms/step - loss: 9.9830 - val_loss: 11.0100\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.9493\n",
      "Epoch 00002: val_loss improved from 11.00997 to 7.31648, saving model to ./storage/precip_rnn/model3/epoch_002_val_loss_7.316.h5\n",
      "196/196 [==============================] - 60s 307ms/step - loss: 6.9449 - val_loss: 7.3165\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5347\n",
      "Epoch 00003: val_loss improved from 7.31648 to 6.20682, saving model to ./storage/precip_rnn/model3/epoch_003_val_loss_6.207.h5\n",
      "196/196 [==============================] - 62s 314ms/step - loss: 5.5321 - val_loss: 6.2068\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2416\n",
      "Epoch 00004: val_loss improved from 6.20682 to 5.14332, saving model to ./storage/precip_rnn/model3/epoch_004_val_loss_5.143.h5\n",
      "196/196 [==============================] - 61s 313ms/step - loss: 5.2373 - val_loss: 5.1433\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.1354\n",
      "Epoch 00005: val_loss improved from 5.14332 to 4.94513, saving model to ./storage/precip_rnn/model3/epoch_005_val_loss_4.945.h5\n",
      "196/196 [==============================] - 62s 318ms/step - loss: 5.1352 - val_loss: 4.9451\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.0337\n",
      "Epoch 00006: val_loss did not improve from 4.94513\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 60s 306ms/step - loss: 5.0335 - val_loss: 5.5930\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8927\n",
      "Epoch 00007: val_loss did not improve from 4.94513\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 4.8904 - val_loss: 5.1387\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8162\n",
      "Epoch 00008: val_loss improved from 4.94513 to 4.77751, saving model to ./storage/precip_rnn/model3/epoch_008_val_loss_4.778.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 4.8144 - val_loss: 4.7775\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7653\n",
      "Epoch 00009: val_loss improved from 4.77751 to 4.72811, saving model to ./storage/precip_rnn/model3/epoch_009_val_loss_4.728.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 4.7674 - val_loss: 4.7281\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7592\n",
      "Epoch 00010: val_loss did not improve from 4.72811\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 4.7617 - val_loss: 4.7690\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6973\n",
      "Epoch 00011: val_loss did not improve from 4.72811\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.6948 - val_loss: 4.8188\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6808\n",
      "Epoch 00012: val_loss improved from 4.72811 to 4.71710, saving model to ./storage/precip_rnn/model3/epoch_012_val_loss_4.717.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.6775 - val_loss: 4.7171\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6802\n",
      "Epoch 00013: val_loss improved from 4.71710 to 4.69111, saving model to ./storage/precip_rnn/model3/epoch_013_val_loss_4.691.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 4.6787 - val_loss: 4.6911\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6555\n",
      "Epoch 00014: val_loss did not improve from 4.69111\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.6654 - val_loss: 4.6923\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6546\n",
      "Epoch 00015: val_loss improved from 4.69111 to 4.68944, saving model to ./storage/precip_rnn/model3/epoch_015_val_loss_4.689.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.6578 - val_loss: 4.6894\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6552\n",
      "Epoch 00016: val_loss did not improve from 4.68944\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.6520 - val_loss: 4.6980\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6410\n",
      "Epoch 00017: val_loss improved from 4.68944 to 4.68788, saving model to ./storage/precip_rnn/model3/epoch_017_val_loss_4.688.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 4.6390 - val_loss: 4.6879\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6390\n",
      "Epoch 00018: val_loss improved from 4.68788 to 4.68076, saving model to ./storage/precip_rnn/model3/epoch_018_val_loss_4.681.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.6359 - val_loss: 4.6808\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6445\n",
      "Epoch 00019: val_loss improved from 4.68076 to 4.67935, saving model to ./storage/precip_rnn/model3/epoch_019_val_loss_4.679.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 4.6454 - val_loss: 4.6793\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6239\n",
      "Epoch 00020: val_loss did not improve from 4.67935\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 4.6253 - val_loss: 4.6801\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6415\n",
      "Epoch 00021: val_loss did not improve from 4.67935\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 4.6425 - val_loss: 4.6796\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6232\n",
      "Epoch 00022: val_loss improved from 4.67935 to 4.67831, saving model to ./storage/precip_rnn/model3/epoch_022_val_loss_4.678.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 4.6254 - val_loss: 4.6783\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6178\n",
      "Epoch 00023: val_loss improved from 4.67831 to 4.67782, saving model to ./storage/precip_rnn/model3/epoch_023_val_loss_4.678.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 4.6133 - val_loss: 4.6778\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6406\n",
      "Epoch 00024: val_loss improved from 4.67782 to 4.67657, saving model to ./storage/precip_rnn/model3/epoch_024_val_loss_4.677.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.6440 - val_loss: 4.6766\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6163\n",
      "Epoch 00025: val_loss did not improve from 4.67657\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.6148 - val_loss: 4.6778\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6238\n",
      "Epoch 00026: val_loss did not improve from 4.67657\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 4.6237 - val_loss: 4.6776\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6079\n",
      "Epoch 00027: val_loss improved from 4.67657 to 4.67613, saving model to ./storage/precip_rnn/model3/epoch_027_val_loss_4.676.h5\n",
      "196/196 [==============================] - 63s 321ms/step - loss: 4.6076 - val_loss: 4.6761\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6347\n",
      "Epoch 00028: val_loss did not improve from 4.67613\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 4.6316 - val_loss: 4.6779\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6185\n",
      "Epoch 00029: val_loss did not improve from 4.67613\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.6173 - val_loss: 4.6776\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6360\n",
      "Epoch 00030: val_loss did not improve from 4.67613\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.6401 - val_loss: 4.6777\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6142\n",
      "Epoch 00031: val_loss did not improve from 4.67613\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 4.6205 - val_loss: 4.6776\n",
      "Epoch 32/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6118\n",
      "Epoch 00032: val_loss did not improve from 4.67613\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 4.6108 - val_loss: 4.6765\n",
      "........ Training model 4 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 10.0750\n",
      "Epoch 00001: val_loss improved from inf to 10.27837, saving model to ./storage/precip_rnn/model4/epoch_001_val_loss_10.278.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 10.0800 - val_loss: 10.2784\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.0251\n",
      "Epoch 00002: val_loss improved from 10.27837 to 7.69771, saving model to ./storage/precip_rnn/model4/epoch_002_val_loss_7.698.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 7.0276 - val_loss: 7.6977\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5781\n",
      "Epoch 00003: val_loss improved from 7.69771 to 5.73234, saving model to ./storage/precip_rnn/model4/epoch_003_val_loss_5.732.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.5740 - val_loss: 5.7323\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3505\n",
      "Epoch 00004: val_loss improved from 5.73234 to 5.23021, saving model to ./storage/precip_rnn/model4/epoch_004_val_loss_5.230.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.3507 - val_loss: 5.2302\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2067\n",
      "Epoch 00005: val_loss improved from 5.23021 to 4.97155, saving model to ./storage/precip_rnn/model4/epoch_005_val_loss_4.972.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 5.2031 - val_loss: 4.9716\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.0966\n",
      "Epoch 00006: val_loss improved from 4.97155 to 4.94126, saving model to ./storage/precip_rnn/model4/epoch_006_val_loss_4.941.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 5.0955 - val_loss: 4.9413\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.9902\n",
      "Epoch 00007: val_loss did not improve from 4.94126\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 4.9947 - val_loss: 5.0276\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8602\n",
      "Epoch 00008: val_loss improved from 4.94126 to 4.75624, saving model to ./storage/precip_rnn/model4/epoch_008_val_loss_4.756.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 4.8615 - val_loss: 4.7562\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8405\n",
      "Epoch 00009: val_loss did not improve from 4.75624\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 4.8373 - val_loss: 5.3925\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7446\n",
      "Epoch 00010: val_loss did not improve from 4.75624\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.7436 - val_loss: 4.8475\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7149\n",
      "Epoch 00011: val_loss improved from 4.75624 to 4.71087, saving model to ./storage/precip_rnn/model4/epoch_011_val_loss_4.711.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.7187 - val_loss: 4.7109\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6903\n",
      "Epoch 00012: val_loss improved from 4.71087 to 4.65591, saving model to ./storage/precip_rnn/model4/epoch_012_val_loss_4.656.h5\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 4.6948 - val_loss: 4.6559\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6825\n",
      "Epoch 00013: val_loss improved from 4.65591 to 4.64575, saving model to ./storage/precip_rnn/model4/epoch_013_val_loss_4.646.h5\n",
      "196/196 [==============================] - 58s 293ms/step - loss: 4.6809 - val_loss: 4.6458\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6793\n",
      "Epoch 00014: val_loss did not improve from 4.64575\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.6823 - val_loss: 4.6509\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6262\n",
      "Epoch 00015: val_loss did not improve from 4.64575\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.6267 - val_loss: 4.7197\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6464\n",
      "Epoch 00016: val_loss improved from 4.64575 to 4.63238, saving model to ./storage/precip_rnn/model4/epoch_016_val_loss_4.632.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 4.6470 - val_loss: 4.6324\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6183\n",
      "Epoch 00017: val_loss did not improve from 4.63238\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.6224 - val_loss: 4.6347\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6203\n",
      "Epoch 00018: val_loss improved from 4.63238 to 4.62956, saving model to ./storage/precip_rnn/model4/epoch_018_val_loss_4.630.h5\n",
      "196/196 [==============================] - 56s 283ms/step - loss: 4.6215 - val_loss: 4.6296\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6059\n",
      "Epoch 00019: val_loss did not improve from 4.62956\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.6073 - val_loss: 4.6407\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6093\n",
      "Epoch 00020: val_loss improved from 4.62956 to 4.62791, saving model to ./storage/precip_rnn/model4/epoch_020_val_loss_4.628.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 4.6127 - val_loss: 4.6279\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6174\n",
      "Epoch 00021: val_loss did not improve from 4.62791\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 4.6173 - val_loss: 4.6281\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6286\n",
      "Epoch 00022: val_loss did not improve from 4.62791\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 4.6296 - val_loss: 4.6297\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6157\n",
      "Epoch 00023: val_loss improved from 4.62791 to 4.62620, saving model to ./storage/precip_rnn/model4/epoch_023_val_loss_4.626.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 4.6130 - val_loss: 4.6262\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6121\n",
      "Epoch 00024: val_loss did not improve from 4.62620\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.6136 - val_loss: 4.6274\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6239\n",
      "Epoch 00025: val_loss did not improve from 4.62620\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.6246 - val_loss: 4.6273\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6084\n",
      "Epoch 00026: val_loss did not improve from 4.62620\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 4.6064 - val_loss: 4.6272\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6049\n",
      "Epoch 00027: val_loss did not improve from 4.62620\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 4.6088 - val_loss: 4.6273\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6210\n",
      "Epoch 00028: val_loss did not improve from 4.62620\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.6161 - val_loss: 4.6269\n",
      "........ Training model 5 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 9.5222\n",
      "Epoch 00001: val_loss improved from inf to 10.31188, saving model to ./storage/precip_rnn/model5/epoch_001_val_loss_10.312.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 9.5108 - val_loss: 10.3119\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.5436\n",
      "Epoch 00002: val_loss improved from 10.31188 to 6.47646, saving model to ./storage/precip_rnn/model5/epoch_002_val_loss_6.476.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 6.5380 - val_loss: 6.4765\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.1476\n",
      "Epoch 00003: val_loss improved from 6.47646 to 4.88796, saving model to ./storage/precip_rnn/model5/epoch_003_val_loss_4.888.h5\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 5.1559 - val_loss: 4.8880\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8910\n",
      "Epoch 00004: val_loss improved from 4.88796 to 4.61118, saving model to ./storage/precip_rnn/model5/epoch_004_val_loss_4.611.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.8960 - val_loss: 4.6112\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7583\n",
      "Epoch 00005: val_loss did not improve from 4.61118\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.7566 - val_loss: 5.1789\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6085\n",
      "Epoch 00006: val_loss improved from 4.61118 to 4.39040, saving model to ./storage/precip_rnn/model5/epoch_006_val_loss_4.390.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.6106 - val_loss: 4.3904\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5495\n",
      "Epoch 00007: val_loss improved from 4.39040 to 4.34318, saving model to ./storage/precip_rnn/model5/epoch_007_val_loss_4.343.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.5462 - val_loss: 4.3432\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5110\n",
      "Epoch 00008: val_loss did not improve from 4.34318\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 4.5136 - val_loss: 4.7935\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.4484\n",
      "Epoch 00009: val_loss improved from 4.34318 to 4.29128, saving model to ./storage/precip_rnn/model5/epoch_009_val_loss_4.291.h5\n",
      "196/196 [==============================] - 59s 299ms/step - loss: 4.4509 - val_loss: 4.2913\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.4141\n",
      "Epoch 00010: val_loss did not improve from 4.29128\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 4.4190 - val_loss: 4.4057\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3528\n",
      "Epoch 00011: val_loss improved from 4.29128 to 4.24479, saving model to ./storage/precip_rnn/model5/epoch_011_val_loss_4.245.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 4.3549 - val_loss: 4.2448\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3628\n",
      "Epoch 00012: val_loss did not improve from 4.24479\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 4.3686 - val_loss: 4.2647\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3364\n",
      "Epoch 00013: val_loss did not improve from 4.24479\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.3381 - val_loss: 4.2609\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3365\n",
      "Epoch 00014: val_loss improved from 4.24479 to 4.24192, saving model to ./storage/precip_rnn/model5/epoch_014_val_loss_4.242.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.3325 - val_loss: 4.2419\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3202\n",
      "Epoch 00015: val_loss improved from 4.24192 to 4.23312, saving model to ./storage/precip_rnn/model5/epoch_015_val_loss_4.233.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.3224 - val_loss: 4.2331\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3159\n",
      "Epoch 00016: val_loss did not improve from 4.23312\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.3148 - val_loss: 4.2527\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3159\n",
      "Epoch 00017: val_loss improved from 4.23312 to 4.22792, saving model to ./storage/precip_rnn/model5/epoch_017_val_loss_4.228.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.3178 - val_loss: 4.2279\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2974\n",
      "Epoch 00018: val_loss did not improve from 4.22792\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.3021 - val_loss: 4.2290\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3016\n",
      "Epoch 00019: val_loss improved from 4.22792 to 4.22492, saving model to ./storage/precip_rnn/model5/epoch_019_val_loss_4.225.h5\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 4.3065 - val_loss: 4.2249\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2982\n",
      "Epoch 00020: val_loss did not improve from 4.22492\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 61s 309ms/step - loss: 4.3005 - val_loss: 4.2254\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2983\n",
      "Epoch 00021: val_loss did not improve from 4.22492\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 4.2975 - val_loss: 4.2258\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3152\n",
      "Epoch 00022: val_loss improved from 4.22492 to 4.22382, saving model to ./storage/precip_rnn/model5/epoch_022_val_loss_4.224.h5\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 4.3146 - val_loss: 4.2238\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3239\n",
      "Epoch 00023: val_loss did not improve from 4.22382\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 59s 303ms/step - loss: 4.3228 - val_loss: 4.2265\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3052\n",
      "Epoch 00024: val_loss did not improve from 4.22382\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 4.3068 - val_loss: 4.2256\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3063\n",
      "Epoch 00025: val_loss did not improve from 4.22382\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 62s 314ms/step - loss: 4.3045 - val_loss: 4.2272\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3085\n",
      "Epoch 00026: val_loss did not improve from 4.22382\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 4.3081 - val_loss: 4.2248\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3022\n",
      "Epoch 00027: val_loss did not improve from 4.22382\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 4.2999 - val_loss: 4.2269\n",
      "........ Training model 6 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 10.0439\n",
      "Epoch 00001: val_loss improved from inf to 10.83993, saving model to ./storage/precip_rnn/model6/epoch_001_val_loss_10.840.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 10.0448 - val_loss: 10.8399\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.7600\n",
      "Epoch 00002: val_loss improved from 10.83993 to 6.05522, saving model to ./storage/precip_rnn/model6/epoch_002_val_loss_6.055.h5\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 6.7526 - val_loss: 6.0552\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.1202\n",
      "Epoch 00003: val_loss improved from 6.05522 to 4.70929, saving model to ./storage/precip_rnn/model6/epoch_003_val_loss_4.709.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.1154 - val_loss: 4.7093\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8462\n",
      "Epoch 00004: val_loss did not improve from 4.70929\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.8479 - val_loss: 4.7411\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6226\n",
      "Epoch 00005: val_loss improved from 4.70929 to 4.40275, saving model to ./storage/precip_rnn/model6/epoch_005_val_loss_4.403.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.6237 - val_loss: 4.4028\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5776\n",
      "Epoch 00006: val_loss did not improve from 4.40275\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.5759 - val_loss: 4.4565\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.4875\n",
      "Epoch 00007: val_loss improved from 4.40275 to 4.33273, saving model to ./storage/precip_rnn/model6/epoch_007_val_loss_4.333.h5\n",
      "196/196 [==============================] - 58s 298ms/step - loss: 4.4855 - val_loss: 4.3327\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.4384\n",
      "Epoch 00008: val_loss improved from 4.33273 to 4.28734, saving model to ./storage/precip_rnn/model6/epoch_008_val_loss_4.287.h5\n",
      "196/196 [==============================] - 61s 309ms/step - loss: 4.4373 - val_loss: 4.2873\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3993\n",
      "Epoch 00009: val_loss improved from 4.28734 to 4.23429, saving model to ./storage/precip_rnn/model6/epoch_009_val_loss_4.234.h5\n",
      "196/196 [==============================] - 62s 314ms/step - loss: 4.4000 - val_loss: 4.2343\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3913\n",
      "Epoch 00010: val_loss improved from 4.23429 to 4.20481, saving model to ./storage/precip_rnn/model6/epoch_010_val_loss_4.205.h5\n",
      "196/196 [==============================] - 60s 304ms/step - loss: 4.3882 - val_loss: 4.2048\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3448\n",
      "Epoch 00011: val_loss did not improve from 4.20481\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 4.3414 - val_loss: 4.3036\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2784\n",
      "Epoch 00012: val_loss did not improve from 4.20481\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 4.2836 - val_loss: 4.2890\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2456\n",
      "Epoch 00013: val_loss improved from 4.20481 to 4.18017, saving model to ./storage/precip_rnn/model6/epoch_013_val_loss_4.180.h5\n",
      "196/196 [==============================] - 62s 316ms/step - loss: 4.2461 - val_loss: 4.1802\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2387\n",
      "Epoch 00014: val_loss improved from 4.18017 to 4.16793, saving model to ./storage/precip_rnn/model6/epoch_014_val_loss_4.168.h5\n",
      "196/196 [==============================] - 60s 304ms/step - loss: 4.2388 - val_loss: 4.1679\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2215\n",
      "Epoch 00015: val_loss improved from 4.16793 to 4.16323, saving model to ./storage/precip_rnn/model6/epoch_015_val_loss_4.163.h5\n",
      "196/196 [==============================] - 58s 298ms/step - loss: 4.2220 - val_loss: 4.1632\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2131\n",
      "Epoch 00016: val_loss did not improve from 4.16323\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 59s 302ms/step - loss: 4.2131 - val_loss: 4.1683\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2365\n",
      "Epoch 00017: val_loss did not improve from 4.16323\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 4.2363 - val_loss: 4.1857\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2132\n",
      "Epoch 00018: val_loss improved from 4.16323 to 4.15155, saving model to ./storage/precip_rnn/model6/epoch_018_val_loss_4.152.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 4.2097 - val_loss: 4.1516\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1879\n",
      "Epoch 00019: val_loss did not improve from 4.15155\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.1914 - val_loss: 4.1534\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2096\n",
      "Epoch 00020: val_loss improved from 4.15155 to 4.14918, saving model to ./storage/precip_rnn/model6/epoch_020_val_loss_4.149.h5\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 4.2099 - val_loss: 4.1492\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2181\n",
      "Epoch 00021: val_loss did not improve from 4.14918\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 4.2178 - val_loss: 4.1515\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2134\n",
      "Epoch 00022: val_loss did not improve from 4.14918\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.2102 - val_loss: 4.1526\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2110\n",
      "Epoch 00023: val_loss did not improve from 4.14918\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.2107 - val_loss: 4.1521\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1894\n",
      "Epoch 00024: val_loss did not improve from 4.14918\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.1930 - val_loss: 4.1508\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2033\n",
      "Epoch 00025: val_loss did not improve from 4.14918\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 4.2020 - val_loss: 4.1537\n",
      "........ Training model 7 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 9.5051\n",
      "Epoch 00001: val_loss improved from inf to 10.08729, saving model to ./storage/precip_rnn/model7/epoch_001_val_loss_10.087.h5\n",
      "196/196 [==============================] - 61s 310ms/step - loss: 9.4962 - val_loss: 10.0873\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.4024\n",
      "Epoch 00002: val_loss improved from 10.08729 to 5.73432, saving model to ./storage/precip_rnn/model7/epoch_002_val_loss_5.734.h5\n",
      "196/196 [==============================] - 62s 318ms/step - loss: 6.4057 - val_loss: 5.7343\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8929\n",
      "Epoch 00003: val_loss improved from 5.73432 to 5.16055, saving model to ./storage/precip_rnn/model7/epoch_003_val_loss_5.161.h5\n",
      "196/196 [==============================] - 63s 321ms/step - loss: 4.8933 - val_loss: 5.1605\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5647\n",
      "Epoch 00004: val_loss improved from 5.16055 to 4.19615, saving model to ./storage/precip_rnn/model7/epoch_004_val_loss_4.196.h5\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 4.5564 - val_loss: 4.1962\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.4135\n",
      "Epoch 00005: val_loss improved from 4.19615 to 4.19548, saving model to ./storage/precip_rnn/model7/epoch_005_val_loss_4.195.h5\n",
      "196/196 [==============================] - 60s 306ms/step - loss: 4.4178 - val_loss: 4.1955\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3851\n",
      "Epoch 00006: val_loss improved from 4.19548 to 4.10414, saving model to ./storage/precip_rnn/model7/epoch_006_val_loss_4.104.h5\n",
      "196/196 [==============================] - 62s 317ms/step - loss: 4.3836 - val_loss: 4.1041\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3251\n",
      "Epoch 00007: val_loss improved from 4.10414 to 4.03395, saving model to ./storage/precip_rnn/model7/epoch_007_val_loss_4.034.h5\n",
      "196/196 [==============================] - 65s 333ms/step - loss: 4.3228 - val_loss: 4.0340\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1894\n",
      "Epoch 00008: val_loss did not improve from 4.03395\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 63s 323ms/step - loss: 4.1880 - val_loss: 4.1921\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1116\n",
      "Epoch 00009: val_loss improved from 4.03395 to 3.92035, saving model to ./storage/precip_rnn/model7/epoch_009_val_loss_3.920.h5\n",
      "196/196 [==============================] - 63s 322ms/step - loss: 4.1089 - val_loss: 3.9203\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.0755\n",
      "Epoch 00010: val_loss did not improve from 3.92035\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 64s 327ms/step - loss: 4.0737 - val_loss: 4.1391\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9897\n",
      "Epoch 00011: val_loss improved from 3.92035 to 3.87168, saving model to ./storage/precip_rnn/model7/epoch_011_val_loss_3.872.h5\n",
      "196/196 [==============================] - 66s 339ms/step - loss: 3.9934 - val_loss: 3.8717\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9368\n",
      "Epoch 00012: val_loss did not improve from 3.87168\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 69s 353ms/step - loss: 3.9380 - val_loss: 3.8930\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9140\n",
      "Epoch 00013: val_loss did not improve from 3.87168\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 64s 328ms/step - loss: 3.9154 - val_loss: 3.9158\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8932\n",
      "Epoch 00014: val_loss improved from 3.87168 to 3.84524, saving model to ./storage/precip_rnn/model7/epoch_014_val_loss_3.845.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 3.8925 - val_loss: 3.8452\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8860\n",
      "Epoch 00015: val_loss did not improve from 3.84524\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 3.8907 - val_loss: 3.8861\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8806\n",
      "Epoch 00016: val_loss improved from 3.84524 to 3.83151, saving model to ./storage/precip_rnn/model7/epoch_016_val_loss_3.832.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 3.8798 - val_loss: 3.8315\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8824\n",
      "Epoch 00017: val_loss did not improve from 3.83151\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 59s 300ms/step - loss: 3.8789 - val_loss: 3.8367\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8790\n",
      "Epoch 00018: val_loss did not improve from 3.83151\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 59s 300ms/step - loss: 3.8812 - val_loss: 3.8359\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8813\n",
      "Epoch 00019: val_loss did not improve from 3.83151\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 59s 302ms/step - loss: 3.8824 - val_loss: 3.8323\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8721\n",
      "Epoch 00020: val_loss did not improve from 3.83151\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 63s 320ms/step - loss: 3.8698 - val_loss: 3.8348\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8477\n",
      "Epoch 00021: val_loss did not improve from 3.83151\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 68s 349ms/step - loss: 3.8479 - val_loss: 3.8337\n",
      "........ Training model 8 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7427\n",
      "Epoch 00001: val_loss improved from inf to 6.79454, saving model to ./storage/precip_rnn/model8/epoch_001_val_loss_6.795.h5\n",
      "196/196 [==============================] - 67s 341ms/step - loss: 5.7419 - val_loss: 6.7945\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9822\n",
      "Epoch 00002: val_loss improved from 6.79454 to 4.30977, saving model to ./storage/precip_rnn/model8/epoch_002_val_loss_4.310.h5\n",
      "196/196 [==============================] - 62s 316ms/step - loss: 3.9857 - val_loss: 4.3098\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5320\n",
      "Epoch 00003: val_loss improved from 4.30977 to 3.92647, saving model to ./storage/precip_rnn/model8/epoch_003_val_loss_3.926.h5\n",
      "196/196 [==============================] - 59s 302ms/step - loss: 3.5326 - val_loss: 3.9265\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.3725\n",
      "Epoch 00004: val_loss improved from 3.92647 to 3.25708, saving model to ./storage/precip_rnn/model8/epoch_004_val_loss_3.257.h5\n",
      "196/196 [==============================] - 62s 315ms/step - loss: 3.3735 - val_loss: 3.2571\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.2338\n",
      "Epoch 00005: val_loss improved from 3.25708 to 3.06156, saving model to ./storage/precip_rnn/model8/epoch_005_val_loss_3.062.h5\n",
      "196/196 [==============================] - 62s 318ms/step - loss: 3.2325 - val_loss: 3.0616\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.1825\n",
      "Epoch 00006: val_loss did not improve from 3.06156\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 59s 303ms/step - loss: 3.1821 - val_loss: 3.1299\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.0910\n",
      "Epoch 00007: val_loss did not improve from 3.06156\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 3.0924 - val_loss: 3.2784\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.0047\n",
      "Epoch 00008: val_loss improved from 3.06156 to 2.94440, saving model to ./storage/precip_rnn/model8/epoch_008_val_loss_2.944.h5\n",
      "196/196 [==============================] - 59s 303ms/step - loss: 3.0056 - val_loss: 2.9444\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9756\n",
      "Epoch 00009: val_loss did not improve from 2.94440\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 61s 313ms/step - loss: 2.9750 - val_loss: 2.9883\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9454\n",
      "Epoch 00010: val_loss improved from 2.94440 to 2.93031, saving model to ./storage/precip_rnn/model8/epoch_010_val_loss_2.930.h5\n",
      "196/196 [==============================] - 63s 319ms/step - loss: 2.9503 - val_loss: 2.9303\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9229\n",
      "Epoch 00011: val_loss improved from 2.93031 to 2.91575, saving model to ./storage/precip_rnn/model8/epoch_011_val_loss_2.916.h5\n",
      "196/196 [==============================] - 61s 312ms/step - loss: 2.9255 - val_loss: 2.9157\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9061\n",
      "Epoch 00012: val_loss did not improve from 2.91575\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 61s 311ms/step - loss: 2.9045 - val_loss: 2.9632\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8840\n",
      "Epoch 00013: val_loss did not improve from 2.91575\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 63s 323ms/step - loss: 2.8816 - val_loss: 2.9564\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8835\n",
      "Epoch 00014: val_loss improved from 2.91575 to 2.90830, saving model to ./storage/precip_rnn/model8/epoch_014_val_loss_2.908.h5\n",
      "196/196 [==============================] - 66s 336ms/step - loss: 2.8822 - val_loss: 2.9083\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8716\n",
      "Epoch 00015: val_loss improved from 2.90830 to 2.90648, saving model to ./storage/precip_rnn/model8/epoch_015_val_loss_2.906.h5\n",
      "196/196 [==============================] - 65s 334ms/step - loss: 2.8725 - val_loss: 2.9065\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8695\n",
      "Epoch 00016: val_loss did not improve from 2.90648\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 61s 314ms/step - loss: 2.8693 - val_loss: 2.9109\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8673\n",
      "Epoch 00017: val_loss improved from 2.90648 to 2.90407, saving model to ./storage/precip_rnn/model8/epoch_017_val_loss_2.904.h5\n",
      "196/196 [==============================] - 62s 314ms/step - loss: 2.8659 - val_loss: 2.9041\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8676\n",
      "Epoch 00018: val_loss did not improve from 2.90407\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 62s 317ms/step - loss: 2.8642 - val_loss: 2.9082\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8535\n",
      "Epoch 00019: val_loss improved from 2.90407 to 2.90403, saving model to ./storage/precip_rnn/model8/epoch_019_val_loss_2.904.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 61s 311ms/step - loss: 2.8562 - val_loss: 2.9040\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8641\n",
      "Epoch 00020: val_loss improved from 2.90403 to 2.90375, saving model to ./storage/precip_rnn/model8/epoch_020_val_loss_2.904.h5\n",
      "196/196 [==============================] - 60s 304ms/step - loss: 2.8619 - val_loss: 2.9037\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8623\n",
      "Epoch 00021: val_loss improved from 2.90375 to 2.90263, saving model to ./storage/precip_rnn/model8/epoch_021_val_loss_2.903.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 2.8629 - val_loss: 2.9026\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8532\n",
      "Epoch 00022: val_loss did not improve from 2.90263\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 2.8523 - val_loss: 2.9034\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8685\n",
      "Epoch 00023: val_loss did not improve from 2.90263\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 60s 306ms/step - loss: 2.8690 - val_loss: 2.9034\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8567\n",
      "Epoch 00024: val_loss improved from 2.90263 to 2.90035, saving model to ./storage/precip_rnn/model8/epoch_024_val_loss_2.900.h5\n",
      "196/196 [==============================] - 62s 314ms/step - loss: 2.8603 - val_loss: 2.9004\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8508\n",
      "Epoch 00025: val_loss did not improve from 2.90035\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 60s 308ms/step - loss: 2.8544 - val_loss: 2.9020\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8590\n",
      "Epoch 00026: val_loss did not improve from 2.90035\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 62s 314ms/step - loss: 2.8585 - val_loss: 2.9032\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8516\n",
      "Epoch 00027: val_loss did not improve from 2.90035\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 63s 324ms/step - loss: 2.8504 - val_loss: 2.9029\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8621\n",
      "Epoch 00028: val_loss did not improve from 2.90035\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 64s 325ms/step - loss: 2.8634 - val_loss: 2.9022\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.8586\n",
      "Epoch 00029: val_loss did not improve from 2.90035\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 63s 320ms/step - loss: 2.8610 - val_loss: 2.9017\n",
      "........ Training model 9 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1329\n",
      "Epoch 00001: val_loss improved from inf to 1.52222, saving model to ./storage/precip_rnn/model9/epoch_001_val_loss_1.522.h5\n",
      "196/196 [==============================] - 60s 307ms/step - loss: 1.1322 - val_loss: 1.5222\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.8082\n",
      "Epoch 00002: val_loss improved from 1.52222 to 1.04852, saving model to ./storage/precip_rnn/model9/epoch_002_val_loss_1.049.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 0.8071 - val_loss: 1.0485\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.7697\n",
      "Epoch 00003: val_loss improved from 1.04852 to 0.80766, saving model to ./storage/precip_rnn/model9/epoch_003_val_loss_0.808.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 0.7682 - val_loss: 0.8077\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.7517\n",
      "Epoch 00004: val_loss improved from 0.80766 to 0.75141, saving model to ./storage/precip_rnn/model9/epoch_004_val_loss_0.751.h5\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 0.7509 - val_loss: 0.7514\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.7324\n",
      "Epoch 00005: val_loss did not improve from 0.75141\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 59s 302ms/step - loss: 0.7320 - val_loss: 0.7520\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.7073\n",
      "Epoch 00006: val_loss improved from 0.75141 to 0.72337, saving model to ./storage/precip_rnn/model9/epoch_006_val_loss_0.723.h5\n",
      "196/196 [==============================] - 58s 298ms/step - loss: 0.7084 - val_loss: 0.7234\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.7033\n",
      "Epoch 00007: val_loss improved from 0.72337 to 0.71589, saving model to ./storage/precip_rnn/model9/epoch_007_val_loss_0.716.h5\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 0.7031 - val_loss: 0.7159\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6938\n",
      "Epoch 00008: val_loss improved from 0.71589 to 0.71348, saving model to ./storage/precip_rnn/model9/epoch_008_val_loss_0.713.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 0.6932 - val_loss: 0.7135\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6871\n",
      "Epoch 00009: val_loss did not improve from 0.71348\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 0.6877 - val_loss: 0.7259\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6736\n",
      "Epoch 00010: val_loss improved from 0.71348 to 0.71302, saving model to ./storage/precip_rnn/model9/epoch_010_val_loss_0.713.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 0.6739 - val_loss: 0.7130\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6706\n",
      "Epoch 00011: val_loss did not improve from 0.71302\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.6707 - val_loss: 0.7132\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6631\n",
      "Epoch 00012: val_loss improved from 0.71302 to 0.71129, saving model to ./storage/precip_rnn/model9/epoch_012_val_loss_0.711.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 0.6622 - val_loss: 0.7113\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6589\n",
      "Epoch 00013: val_loss improved from 0.71129 to 0.70788, saving model to ./storage/precip_rnn/model9/epoch_013_val_loss_0.708.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 0.6600 - val_loss: 0.7079\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6580\n",
      "Epoch 00014: val_loss improved from 0.70788 to 0.70764, saving model to ./storage/precip_rnn/model9/epoch_014_val_loss_0.708.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 0.6581 - val_loss: 0.7076\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6577\n",
      "Epoch 00015: val_loss did not improve from 0.70764\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 0.6582 - val_loss: 0.7115\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6545\n",
      "Epoch 00016: val_loss improved from 0.70764 to 0.70668, saving model to ./storage/precip_rnn/model9/epoch_016_val_loss_0.707.h5\n",
      "196/196 [==============================] - 59s 303ms/step - loss: 0.6546 - val_loss: 0.7067\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6513\n",
      "Epoch 00017: val_loss improved from 0.70668 to 0.70648, saving model to ./storage/precip_rnn/model9/epoch_017_val_loss_0.706.h5\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 0.6515 - val_loss: 0.7065\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6511\n",
      "Epoch 00018: val_loss did not improve from 0.70648\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 58s 298ms/step - loss: 0.6527 - val_loss: 0.7067\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6488\n",
      "Epoch 00019: val_loss did not improve from 0.70648\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 0.6489 - val_loss: 0.7071\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6494\n",
      "Epoch 00020: val_loss improved from 0.70648 to 0.70591, saving model to ./storage/precip_rnn/model9/epoch_020_val_loss_0.706.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 0.6491 - val_loss: 0.7059\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6487\n",
      "Epoch 00021: val_loss did not improve from 0.70591\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.6477 - val_loss: 0.7062\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6485\n",
      "Epoch 00022: val_loss did not improve from 0.70591\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.6482 - val_loss: 0.7060\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6477\n",
      "Epoch 00023: val_loss did not improve from 0.70591\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 0.6474 - val_loss: 0.7060\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6473\n",
      "Epoch 00024: val_loss improved from 0.70591 to 0.70591, saving model to ./storage/precip_rnn/model9/epoch_024_val_loss_0.706.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.6475 - val_loss: 0.7059\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6461\n",
      "Epoch 00025: val_loss did not improve from 0.70591\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 0.6465 - val_loss: 0.7059\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6482\n",
      "Epoch 00026: val_loss improved from 0.70591 to 0.70589, saving model to ./storage/precip_rnn/model9/epoch_026_val_loss_0.706.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 0.6473 - val_loss: 0.7059\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6469\n",
      "Epoch 00027: val_loss improved from 0.70589 to 0.70587, saving model to ./storage/precip_rnn/model9/epoch_027_val_loss_0.706.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 0.6469 - val_loss: 0.7059\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6470\n",
      "Epoch 00028: val_loss improved from 0.70587 to 0.70527, saving model to ./storage/precip_rnn/model9/epoch_028_val_loss_0.705.h5\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 0.6473 - val_loss: 0.7053\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6475\n",
      "Epoch 00029: val_loss did not improve from 0.70527\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 59s 299ms/step - loss: 0.6472 - val_loss: 0.7059\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6473\n",
      "Epoch 00030: val_loss did not improve from 0.70527\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 0.6470 - val_loss: 0.7059\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6468\n",
      "Epoch 00031: val_loss did not improve from 0.70527\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 0.6474 - val_loss: 0.7059\n",
      "Epoch 32/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6475\n",
      "Epoch 00032: val_loss did not improve from 0.70527\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 0.6469 - val_loss: 0.7059\n",
      "Epoch 33/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.6454\n",
      "Epoch 00033: val_loss did not improve from 0.70527\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 0.6465 - val_loss: 0.7059\n",
      "........ Training model 10 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00001: val_loss improved from inf to 0.00000, saving model to ./storage/precip_rnn/model10/epoch_001_val_loss_0.000.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00002: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00003: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00004: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00005: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.0000e+00\n",
      "Epoch 00006: val_loss did not improve from 0.00000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "........ Training model 11 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.4076\n",
      "Epoch 00001: val_loss improved from inf to 3.48356, saving model to ./storage/precip_rnn/model11/epoch_001_val_loss_3.484.h5\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 2.4035 - val_loss: 3.4836\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.5359\n",
      "Epoch 00002: val_loss improved from 3.48356 to 2.19546, saving model to ./storage/precip_rnn/model11/epoch_002_val_loss_2.195.h5\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 1.5344 - val_loss: 2.1955\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.4019\n",
      "Epoch 00003: val_loss improved from 2.19546 to 1.31639, saving model to ./storage/precip_rnn/model11/epoch_003_val_loss_1.316.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 1.4007 - val_loss: 1.3164\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.3547\n",
      "Epoch 00004: val_loss improved from 1.31639 to 1.25351, saving model to ./storage/precip_rnn/model11/epoch_004_val_loss_1.254.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 1.3542 - val_loss: 1.2535\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.3222\n",
      "Epoch 00005: val_loss did not improve from 1.25351\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 1.3232 - val_loss: 1.2976\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.2790\n",
      "Epoch 00006: val_loss did not improve from 1.25351\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 57s 288ms/step - loss: 1.2794 - val_loss: 1.3477\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.2400\n",
      "Epoch 00007: val_loss improved from 1.25351 to 1.19755, saving model to ./storage/precip_rnn/model11/epoch_007_val_loss_1.198.h5\n",
      "196/196 [==============================] - 62s 315ms/step - loss: 1.2383 - val_loss: 1.1975\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.2289\n",
      "Epoch 00008: val_loss did not improve from 1.19755\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 64s 328ms/step - loss: 1.2306 - val_loss: 1.2371\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.2140\n",
      "Epoch 00009: val_loss improved from 1.19755 to 1.19257, saving model to ./storage/precip_rnn/model11/epoch_009_val_loss_1.193.h5\n",
      "196/196 [==============================] - 66s 335ms/step - loss: 1.2146 - val_loss: 1.1926\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.2096\n",
      "Epoch 00010: val_loss did not improve from 1.19257\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 66s 335ms/step - loss: 1.2085 - val_loss: 1.2197\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.2084\n",
      "Epoch 00011: val_loss improved from 1.19257 to 1.18837, saving model to ./storage/precip_rnn/model11/epoch_011_val_loss_1.188.h5\n",
      "196/196 [==============================] - 67s 344ms/step - loss: 1.2079 - val_loss: 1.1884\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1991\n",
      "Epoch 00012: val_loss improved from 1.18837 to 1.18806, saving model to ./storage/precip_rnn/model11/epoch_012_val_loss_1.188.h5\n",
      "196/196 [==============================] - 67s 344ms/step - loss: 1.1979 - val_loss: 1.1881\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1995\n",
      "Epoch 00013: val_loss did not improve from 1.18806\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 62s 317ms/step - loss: 1.1998 - val_loss: 1.1889\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1915\n",
      "Epoch 00014: val_loss improved from 1.18806 to 1.18562, saving model to ./storage/precip_rnn/model11/epoch_014_val_loss_1.186.h5\n",
      "196/196 [==============================] - 59s 303ms/step - loss: 1.1914 - val_loss: 1.1856\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1959\n",
      "Epoch 00015: val_loss did not improve from 1.18562\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 59s 299ms/step - loss: 1.1956 - val_loss: 1.1912\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1839\n",
      "Epoch 00016: val_loss improved from 1.18562 to 1.18506, saving model to ./storage/precip_rnn/model11/epoch_016_val_loss_1.185.h5\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 1.1842 - val_loss: 1.1851\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1888\n",
      "Epoch 00017: val_loss improved from 1.18506 to 1.18467, saving model to ./storage/precip_rnn/model11/epoch_017_val_loss_1.185.h5\n",
      "196/196 [==============================] - 60s 304ms/step - loss: 1.1888 - val_loss: 1.1847\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1909\n",
      "Epoch 00018: val_loss did not improve from 1.18467\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 60s 306ms/step - loss: 1.1907 - val_loss: 1.1861\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1860\n",
      "Epoch 00019: val_loss improved from 1.18467 to 1.18437, saving model to ./storage/precip_rnn/model11/epoch_019_val_loss_1.184.h5\n",
      "196/196 [==============================] - 63s 321ms/step - loss: 1.1857 - val_loss: 1.1844\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1838\n",
      "Epoch 00020: val_loss did not improve from 1.18437\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 60s 304ms/step - loss: 1.1846 - val_loss: 1.1846\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1830\n",
      "Epoch 00021: val_loss improved from 1.18437 to 1.18409, saving model to ./storage/precip_rnn/model11/epoch_021_val_loss_1.184.h5\n",
      "196/196 [==============================] - 60s 307ms/step - loss: 1.1828 - val_loss: 1.1841\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1845\n",
      "Epoch 00022: val_loss improved from 1.18409 to 1.18388, saving model to ./storage/precip_rnn/model11/epoch_022_val_loss_1.184.h5\n",
      "196/196 [==============================] - 59s 302ms/step - loss: 1.1826 - val_loss: 1.1839\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1866\n",
      "Epoch 00023: val_loss did not improve from 1.18388\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 61s 311ms/step - loss: 1.1873 - val_loss: 1.1845\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1871\n",
      "Epoch 00024: val_loss did not improve from 1.18388\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 1.1864 - val_loss: 1.1846\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1813\n",
      "Epoch 00025: val_loss did not improve from 1.18388\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 1.1819 - val_loss: 1.1845\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1870\n",
      "Epoch 00026: val_loss did not improve from 1.18388\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 1.1860 - val_loss: 1.1844\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 1.1877\n",
      "Epoch 00027: val_loss did not improve from 1.18388\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 1.1882 - val_loss: 1.1844\n",
      "........ Training model 12 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 10.4245\n",
      "Epoch 00001: val_loss improved from inf to 10.76242, saving model to ./storage/precip_rnn/model12/epoch_001_val_loss_10.762.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 10.4234 - val_loss: 10.7624\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.1817\n",
      "Epoch 00002: val_loss improved from 10.76242 to 6.51078, saving model to ./storage/precip_rnn/model12/epoch_002_val_loss_6.511.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 7.1756 - val_loss: 6.5108\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5250\n",
      "Epoch 00003: val_loss improved from 6.51078 to 5.09333, saving model to ./storage/precip_rnn/model12/epoch_003_val_loss_5.093.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 5.5260 - val_loss: 5.0933\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.1725\n",
      "Epoch 00004: val_loss did not improve from 5.09333\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.1724 - val_loss: 5.2661\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.9966\n",
      "Epoch 00005: val_loss improved from 5.09333 to 4.89326, saving model to ./storage/precip_rnn/model12/epoch_005_val_loss_4.893.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.9966 - val_loss: 4.8933\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.9650\n",
      "Epoch 00006: val_loss did not improve from 4.89326\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 4.9692 - val_loss: 4.9042\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8223\n",
      "Epoch 00007: val_loss improved from 4.89326 to 4.72955, saving model to ./storage/precip_rnn/model12/epoch_007_val_loss_4.730.h5\n",
      "196/196 [==============================] - 60s 304ms/step - loss: 4.8226 - val_loss: 4.7296\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7970\n",
      "Epoch 00008: val_loss improved from 4.72955 to 4.62670, saving model to ./storage/precip_rnn/model12/epoch_008_val_loss_4.627.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.7954 - val_loss: 4.6267\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7738\n",
      "Epoch 00009: val_loss improved from 4.62670 to 4.61869, saving model to ./storage/precip_rnn/model12/epoch_009_val_loss_4.619.h5\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.7755 - val_loss: 4.6187\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7217\n",
      "Epoch 00010: val_loss did not improve from 4.61869\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 4.7244 - val_loss: 4.6194\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7015\n",
      "Epoch 00011: val_loss improved from 4.61869 to 4.57576, saving model to ./storage/precip_rnn/model12/epoch_011_val_loss_4.576.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.7031 - val_loss: 4.5758\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6565\n",
      "Epoch 00012: val_loss improved from 4.57576 to 4.55605, saving model to ./storage/precip_rnn/model12/epoch_012_val_loss_4.556.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.6505 - val_loss: 4.5560\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6404\n",
      "Epoch 00013: val_loss improved from 4.55605 to 4.55355, saving model to ./storage/precip_rnn/model12/epoch_013_val_loss_4.554.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 4.6368 - val_loss: 4.5535\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6452\n",
      "Epoch 00014: val_loss improved from 4.55355 to 4.55262, saving model to ./storage/precip_rnn/model12/epoch_014_val_loss_4.553.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 4.6445 - val_loss: 4.5526\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6423\n",
      "Epoch 00015: val_loss improved from 4.55262 to 4.54298, saving model to ./storage/precip_rnn/model12/epoch_015_val_loss_4.543.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 4.6460 - val_loss: 4.5430\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6034\n",
      "Epoch 00016: val_loss did not improve from 4.54298\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 4.6043 - val_loss: 4.6210\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5973\n",
      "Epoch 00017: val_loss improved from 4.54298 to 4.53056, saving model to ./storage/precip_rnn/model12/epoch_017_val_loss_4.531.h5\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 4.5966 - val_loss: 4.5306\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5765\n",
      "Epoch 00018: val_loss did not improve from 4.53056\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.5799 - val_loss: 4.5326\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5797\n",
      "Epoch 00019: val_loss improved from 4.53056 to 4.51891, saving model to ./storage/precip_rnn/model12/epoch_019_val_loss_4.519.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.5822 - val_loss: 4.5189\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5466\n",
      "Epoch 00020: val_loss did not improve from 4.51891\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 4.5438 - val_loss: 4.5325\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5330\n",
      "Epoch 00021: val_loss improved from 4.51891 to 4.51091, saving model to ./storage/precip_rnn/model12/epoch_021_val_loss_4.511.h5\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 4.5322 - val_loss: 4.5109\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5442\n",
      "Epoch 00022: val_loss did not improve from 4.51091\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 4.5431 - val_loss: 4.5218\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5472\n",
      "Epoch 00023: val_loss improved from 4.51091 to 4.50888, saving model to ./storage/precip_rnn/model12/epoch_023_val_loss_4.509.h5\n",
      "196/196 [==============================] - 60s 305ms/step - loss: 4.5468 - val_loss: 4.5089\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5413\n",
      "Epoch 00024: val_loss improved from 4.50888 to 4.50735, saving model to ./storage/precip_rnn/model12/epoch_024_val_loss_4.507.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.5383 - val_loss: 4.5073\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5338\n",
      "Epoch 00025: val_loss did not improve from 4.50735\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.5325 - val_loss: 4.5095\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5368\n",
      "Epoch 00026: val_loss improved from 4.50735 to 4.50586, saving model to ./storage/precip_rnn/model12/epoch_026_val_loss_4.506.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 4.5326 - val_loss: 4.5059\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5366\n",
      "Epoch 00027: val_loss did not improve from 4.50586\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.5400 - val_loss: 4.5075\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5384\n",
      "Epoch 00028: val_loss improved from 4.50586 to 4.50554, saving model to ./storage/precip_rnn/model12/epoch_028_val_loss_4.506.h5\n",
      "196/196 [==============================] - 57s 288ms/step - loss: 4.5389 - val_loss: 4.5055\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5117\n",
      "Epoch 00029: val_loss improved from 4.50554 to 4.50518, saving model to ./storage/precip_rnn/model12/epoch_029_val_loss_4.505.h5\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 4.5137 - val_loss: 4.5052\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5398\n",
      "Epoch 00030: val_loss did not improve from 4.50518\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 4.5382 - val_loss: 4.5054\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5405\n",
      "Epoch 00031: val_loss did not improve from 4.50518\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 4.5408 - val_loss: 4.5085\n",
      "Epoch 32/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5465\n",
      "Epoch 00032: val_loss did not improve from 4.50518\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 4.5435 - val_loss: 4.5076\n",
      "Epoch 33/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5343\n",
      "Epoch 00033: val_loss did not improve from 4.50518\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.5302 - val_loss: 4.5069\n",
      "Epoch 34/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5615\n",
      "Epoch 00034: val_loss did not improve from 4.50518\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 4.5661 - val_loss: 4.5076\n",
      "........ Training model 13 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 12.5176\n",
      "Epoch 00001: val_loss improved from inf to 12.50227, saving model to ./storage/precip_rnn/model13/epoch_001_val_loss_12.502.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 12.5051 - val_loss: 12.5023\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 8.8954\n",
      "Epoch 00002: val_loss improved from 12.50227 to 9.88008, saving model to ./storage/precip_rnn/model13/epoch_002_val_loss_9.880.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 8.8879 - val_loss: 9.8801\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.6489\n",
      "Epoch 00003: val_loss improved from 9.88008 to 6.72233, saving model to ./storage/precip_rnn/model13/epoch_003_val_loss_6.722.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 6.6453 - val_loss: 6.7223\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.2282\n",
      "Epoch 00004: val_loss improved from 6.72233 to 6.01816, saving model to ./storage/precip_rnn/model13/epoch_004_val_loss_6.018.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 6.2337 - val_loss: 6.0182\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.0732\n",
      "Epoch 00005: val_loss improved from 6.01816 to 5.91778, saving model to ./storage/precip_rnn/model13/epoch_005_val_loss_5.918.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 6.0688 - val_loss: 5.9178\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.9378\n",
      "Epoch 00006: val_loss did not improve from 5.91778\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.9342 - val_loss: 5.9581\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7489\n",
      "Epoch 00007: val_loss improved from 5.91778 to 5.71697, saving model to ./storage/precip_rnn/model13/epoch_007_val_loss_5.717.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.7446 - val_loss: 5.7170\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7003\n",
      "Epoch 00008: val_loss improved from 5.71697 to 5.67489, saving model to ./storage/precip_rnn/model13/epoch_008_val_loss_5.675.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 5.6953 - val_loss: 5.6749\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6608\n",
      "Epoch 00009: val_loss did not improve from 5.67489\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 5.6624 - val_loss: 6.0314\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5718\n",
      "Epoch 00010: val_loss did not improve from 5.67489\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 5.5715 - val_loss: 5.7014\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5252\n",
      "Epoch 00011: val_loss improved from 5.67489 to 5.49101, saving model to ./storage/precip_rnn/model13/epoch_011_val_loss_5.491.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 5.5242 - val_loss: 5.4910\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5076\n",
      "Epoch 00012: val_loss improved from 5.49101 to 5.48175, saving model to ./storage/precip_rnn/model13/epoch_012_val_loss_5.482.h5\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 5.5070 - val_loss: 5.4817\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4797\n",
      "Epoch 00013: val_loss did not improve from 5.48175\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.4791 - val_loss: 5.6521\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4742\n",
      "Epoch 00014: val_loss improved from 5.48175 to 5.47479, saving model to ./storage/precip_rnn/model13/epoch_014_val_loss_5.475.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.4711 - val_loss: 5.4748\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4479\n",
      "Epoch 00015: val_loss improved from 5.47479 to 5.44916, saving model to ./storage/precip_rnn/model13/epoch_015_val_loss_5.449.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.4445 - val_loss: 5.4492\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4348\n",
      "Epoch 00016: val_loss improved from 5.44916 to 5.44566, saving model to ./storage/precip_rnn/model13/epoch_016_val_loss_5.446.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 5.4344 - val_loss: 5.4457\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4397\n",
      "Epoch 00017: val_loss did not improve from 5.44566\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 56s 283ms/step - loss: 5.4422 - val_loss: 5.4593\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4358\n",
      "Epoch 00018: val_loss did not improve from 5.44566\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.4353 - val_loss: 5.4864\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4490\n",
      "Epoch 00019: val_loss improved from 5.44566 to 5.43973, saving model to ./storage/precip_rnn/model13/epoch_019_val_loss_5.440.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 5.4455 - val_loss: 5.4397\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4050\n",
      "Epoch 00020: val_loss improved from 5.43973 to 5.43851, saving model to ./storage/precip_rnn/model13/epoch_020_val_loss_5.439.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.4116 - val_loss: 5.4385\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4234\n",
      "Epoch 00021: val_loss did not improve from 5.43851\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 5.4203 - val_loss: 5.4424\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3820\n",
      "Epoch 00022: val_loss improved from 5.43851 to 5.43602, saving model to ./storage/precip_rnn/model13/epoch_022_val_loss_5.436.h5\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 5.3867 - val_loss: 5.4360\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3974\n",
      "Epoch 00023: val_loss did not improve from 5.43602\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 5.3989 - val_loss: 5.4497\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4013\n",
      "Epoch 00024: val_loss did not improve from 5.43602\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 5.3975 - val_loss: 5.4383\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4151\n",
      "Epoch 00025: val_loss improved from 5.43602 to 5.43544, saving model to ./storage/precip_rnn/model13/epoch_025_val_loss_5.435.h5\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 5.4124 - val_loss: 5.4354\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4198\n",
      "Epoch 00026: val_loss improved from 5.43544 to 5.43470, saving model to ./storage/precip_rnn/model13/epoch_026_val_loss_5.435.h5\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 5.4213 - val_loss: 5.4347\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4195\n",
      "Epoch 00027: val_loss did not improve from 5.43470\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 5.4152 - val_loss: 5.4360\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4372\n",
      "Epoch 00028: val_loss did not improve from 5.43470\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.4342 - val_loss: 5.4359\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4054\n",
      "Epoch 00029: val_loss did not improve from 5.43470\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 5.4087 - val_loss: 5.4361\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4168\n",
      "Epoch 00030: val_loss did not improve from 5.43470\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 5.4126 - val_loss: 5.4354\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4155\n",
      "Epoch 00031: val_loss did not improve from 5.43470\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 5.4140 - val_loss: 5.4353\n",
      "........ Training model 14 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 13.3229\n",
      "Epoch 00001: val_loss improved from inf to 13.20256, saving model to ./storage/precip_rnn/model14/epoch_001_val_loss_13.203.h5\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 13.3035 - val_loss: 13.2026\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 9.3989\n",
      "Epoch 00002: val_loss improved from 13.20256 to 8.34700, saving model to ./storage/precip_rnn/model14/epoch_002_val_loss_8.347.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 9.4009 - val_loss: 8.3470\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.0920\n",
      "Epoch 00003: val_loss improved from 8.34700 to 6.67915, saving model to ./storage/precip_rnn/model14/epoch_003_val_loss_6.679.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 7.0886 - val_loss: 6.6791\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.6197\n",
      "Epoch 00004: val_loss improved from 6.67915 to 6.17419, saving model to ./storage/precip_rnn/model14/epoch_004_val_loss_6.174.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 6.6185 - val_loss: 6.1742\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.3969\n",
      "Epoch 00005: val_loss improved from 6.17419 to 6.09926, saving model to ./storage/precip_rnn/model14/epoch_005_val_loss_6.099.h5\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 6.3987 - val_loss: 6.0993\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.3212\n",
      "Epoch 00006: val_loss improved from 6.09926 to 5.95877, saving model to ./storage/precip_rnn/model14/epoch_006_val_loss_5.959.h5\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 6.3205 - val_loss: 5.9588\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.2394\n",
      "Epoch 00007: val_loss improved from 5.95877 to 5.94248, saving model to ./storage/precip_rnn/model14/epoch_007_val_loss_5.942.h5\n",
      "196/196 [==============================] - 59s 299ms/step - loss: 6.2388 - val_loss: 5.9425\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.1265\n",
      "Epoch 00008: val_loss improved from 5.94248 to 5.92225, saving model to ./storage/precip_rnn/model14/epoch_008_val_loss_5.922.h5\n",
      "196/196 [==============================] - 59s 300ms/step - loss: 6.1232 - val_loss: 5.9222\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.0427\n",
      "Epoch 00009: val_loss did not improve from 5.92225\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 6.0385 - val_loss: 6.3982\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.9136\n",
      "Epoch 00010: val_loss improved from 5.92225 to 5.69565, saving model to ./storage/precip_rnn/model14/epoch_010_val_loss_5.696.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 5.9106 - val_loss: 5.6957\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8829\n",
      "Epoch 00011: val_loss did not improve from 5.69565\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.8790 - val_loss: 5.7616\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7809\n",
      "Epoch 00012: val_loss did not improve from 5.69565\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.7769 - val_loss: 5.7613\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7195\n",
      "Epoch 00013: val_loss improved from 5.69565 to 5.64009, saving model to ./storage/precip_rnn/model14/epoch_013_val_loss_5.640.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.7219 - val_loss: 5.6401\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7240\n",
      "Epoch 00014: val_loss did not improve from 5.64009\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.7277 - val_loss: 5.6467\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6899\n",
      "Epoch 00015: val_loss improved from 5.64009 to 5.58997, saving model to ./storage/precip_rnn/model14/epoch_015_val_loss_5.590.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.6891 - val_loss: 5.5900\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6637\n",
      "Epoch 00016: val_loss improved from 5.58997 to 5.57704, saving model to ./storage/precip_rnn/model14/epoch_016_val_loss_5.577.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 5.6616 - val_loss: 5.5770\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6649\n",
      "Epoch 00017: val_loss did not improve from 5.57704\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 57s 288ms/step - loss: 5.6651 - val_loss: 5.6663\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6545\n",
      "Epoch 00018: val_loss improved from 5.57704 to 5.56665, saving model to ./storage/precip_rnn/model14/epoch_018_val_loss_5.567.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 5.6517 - val_loss: 5.5667\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6580\n",
      "Epoch 00019: val_loss improved from 5.56665 to 5.56606, saving model to ./storage/precip_rnn/model14/epoch_019_val_loss_5.566.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 5.6572 - val_loss: 5.5661\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6510\n",
      "Epoch 00020: val_loss did not improve from 5.56606\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 5.6482 - val_loss: 5.5662\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6437\n",
      "Epoch 00021: val_loss improved from 5.56606 to 5.55617, saving model to ./storage/precip_rnn/model14/epoch_021_val_loss_5.556.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 5.6436 - val_loss: 5.5562\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6379\n",
      "Epoch 00022: val_loss did not improve from 5.55617\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 5.6354 - val_loss: 5.5563\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6305\n",
      "Epoch 00023: val_loss did not improve from 5.55617\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.6328 - val_loss: 5.5574\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6312\n",
      "Epoch 00024: val_loss improved from 5.55617 to 5.55613, saving model to ./storage/precip_rnn/model14/epoch_024_val_loss_5.556.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 5.6341 - val_loss: 5.5561\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6163\n",
      "Epoch 00025: val_loss improved from 5.55613 to 5.55360, saving model to ./storage/precip_rnn/model14/epoch_025_val_loss_5.554.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.6205 - val_loss: 5.5536\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6190\n",
      "Epoch 00026: val_loss did not improve from 5.55360\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.6134 - val_loss: 5.5537\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6214\n",
      "Epoch 00027: val_loss did not improve from 5.55360\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.6234 - val_loss: 5.5537\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6342\n",
      "Epoch 00028: val_loss did not improve from 5.55360\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 5.6329 - val_loss: 5.5541\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6297\n",
      "Epoch 00029: val_loss did not improve from 5.55360\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 5.6330 - val_loss: 5.5571\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6208\n",
      "Epoch 00030: val_loss did not improve from 5.55360\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.6234 - val_loss: 5.5567\n",
      "........ Training model 15 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 12.1521\n",
      "Epoch 00001: val_loss improved from inf to 11.65003, saving model to ./storage/precip_rnn/model15/epoch_001_val_loss_11.650.h5\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 12.1505 - val_loss: 11.6500\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 8.4851\n",
      "Epoch 00002: val_loss improved from 11.65003 to 8.25024, saving model to ./storage/precip_rnn/model15/epoch_002_val_loss_8.250.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 8.4736 - val_loss: 8.2502\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.0386\n",
      "Epoch 00003: val_loss improved from 8.25024 to 6.23931, saving model to ./storage/precip_rnn/model15/epoch_003_val_loss_6.239.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 6.0322 - val_loss: 6.2393\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6145\n",
      "Epoch 00004: val_loss improved from 6.23931 to 5.24224, saving model to ./storage/precip_rnn/model15/epoch_004_val_loss_5.242.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 5.6151 - val_loss: 5.2422\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5052\n",
      "Epoch 00005: val_loss improved from 5.24224 to 5.16818, saving model to ./storage/precip_rnn/model15/epoch_005_val_loss_5.168.h5\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 5.5044 - val_loss: 5.1682\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3066\n",
      "Epoch 00006: val_loss improved from 5.16818 to 5.15491, saving model to ./storage/precip_rnn/model15/epoch_006_val_loss_5.155.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 5.3069 - val_loss: 5.1549\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2187\n",
      "Epoch 00007: val_loss improved from 5.15491 to 5.08533, saving model to ./storage/precip_rnn/model15/epoch_007_val_loss_5.085.h5\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 5.2232 - val_loss: 5.0853\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.1582\n",
      "Epoch 00008: val_loss improved from 5.08533 to 5.00639, saving model to ./storage/precip_rnn/model15/epoch_008_val_loss_5.006.h5\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 5.1610 - val_loss: 5.0064\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.1294\n",
      "Epoch 00009: val_loss did not improve from 5.00639\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 5.1264 - val_loss: 5.0953\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.9384\n",
      "Epoch 00010: val_loss improved from 5.00639 to 4.89110, saving model to ./storage/precip_rnn/model15/epoch_010_val_loss_4.891.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.9463 - val_loss: 4.8911\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.9014\n",
      "Epoch 00011: val_loss improved from 4.89110 to 4.86174, saving model to ./storage/precip_rnn/model15/epoch_011_val_loss_4.862.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 4.9022 - val_loss: 4.8617\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8713\n",
      "Epoch 00012: val_loss improved from 4.86174 to 4.84803, saving model to ./storage/precip_rnn/model15/epoch_012_val_loss_4.848.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.8758 - val_loss: 4.8480\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8326\n",
      "Epoch 00013: val_loss did not improve from 4.84803\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.8309 - val_loss: 4.9273\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7860\n",
      "Epoch 00014: val_loss improved from 4.84803 to 4.79673, saving model to ./storage/precip_rnn/model15/epoch_014_val_loss_4.797.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.7848 - val_loss: 4.7967\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7465\n",
      "Epoch 00015: val_loss improved from 4.79673 to 4.77192, saving model to ./storage/precip_rnn/model15/epoch_015_val_loss_4.772.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.7420 - val_loss: 4.7719\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7311\n",
      "Epoch 00016: val_loss improved from 4.77192 to 4.75807, saving model to ./storage/precip_rnn/model15/epoch_016_val_loss_4.758.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 4.7319 - val_loss: 4.7581\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7144\n",
      "Epoch 00017: val_loss did not improve from 4.75807\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 4.7186 - val_loss: 4.7963\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6656\n",
      "Epoch 00018: val_loss did not improve from 4.75807\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 4.6692 - val_loss: 4.7740\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6522\n",
      "Epoch 00019: val_loss improved from 4.75807 to 4.75355, saving model to ./storage/precip_rnn/model15/epoch_019_val_loss_4.754.h5\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 4.6517 - val_loss: 4.7535\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6348\n",
      "Epoch 00020: val_loss improved from 4.75355 to 4.73444, saving model to ./storage/precip_rnn/model15/epoch_020_val_loss_4.734.h5\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 4.6347 - val_loss: 4.7344\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6473\n",
      "Epoch 00021: val_loss did not improve from 4.73444\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 4.6459 - val_loss: 4.7383\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6323\n",
      "Epoch 00022: val_loss improved from 4.73444 to 4.73078, saving model to ./storage/precip_rnn/model15/epoch_022_val_loss_4.731.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 4.6302 - val_loss: 4.7308\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6283\n",
      "Epoch 00023: val_loss did not improve from 4.73078\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.6298 - val_loss: 4.7375\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6100\n",
      "Epoch 00024: val_loss did not improve from 4.73078\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.6167 - val_loss: 4.7325\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6162\n",
      "Epoch 00025: val_loss did not improve from 4.73078\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 59s 299ms/step - loss: 4.6217 - val_loss: 4.7320\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6080\n",
      "Epoch 00026: val_loss did not improve from 4.73078\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.6098 - val_loss: 4.7326\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6052\n",
      "Epoch 00027: val_loss did not improve from 4.73078\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.6066 - val_loss: 4.7336\n",
      "........ Training model 16 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 11.4260\n",
      "Epoch 00001: val_loss improved from inf to 11.09147, saving model to ./storage/precip_rnn/model16/epoch_001_val_loss_11.091.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 11.4274 - val_loss: 11.0915\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.7914\n",
      "Epoch 00002: val_loss improved from 11.09147 to 6.84071, saving model to ./storage/precip_rnn/model16/epoch_002_val_loss_6.841.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 7.7749 - val_loss: 6.8407\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5987\n",
      "Epoch 00003: val_loss improved from 6.84071 to 5.60710, saving model to ./storage/precip_rnn/model16/epoch_003_val_loss_5.607.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 5.6002 - val_loss: 5.6071\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2315\n",
      "Epoch 00004: val_loss improved from 5.60710 to 5.32250, saving model to ./storage/precip_rnn/model16/epoch_004_val_loss_5.323.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.2275 - val_loss: 5.3225\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.0978\n",
      "Epoch 00005: val_loss improved from 5.32250 to 5.05135, saving model to ./storage/precip_rnn/model16/epoch_005_val_loss_5.051.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 5.1000 - val_loss: 5.0514\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.9736\n",
      "Epoch 00006: val_loss did not improve from 5.05135\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 4.9725 - val_loss: 5.0650\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.8456\n",
      "Epoch 00007: val_loss improved from 5.05135 to 4.68629, saving model to ./storage/precip_rnn/model16/epoch_007_val_loss_4.686.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 4.8443 - val_loss: 4.6863\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.7533\n",
      "Epoch 00008: val_loss did not improve from 4.68629\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 4.7539 - val_loss: 5.3330\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6861\n",
      "Epoch 00009: val_loss improved from 4.68629 to 4.63219, saving model to ./storage/precip_rnn/model16/epoch_009_val_loss_4.632.h5\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 4.6852 - val_loss: 4.6322\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6587\n",
      "Epoch 00010: val_loss did not improve from 4.63219\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 4.6572 - val_loss: 4.7333\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6104\n",
      "Epoch 00011: val_loss improved from 4.63219 to 4.58040, saving model to ./storage/precip_rnn/model16/epoch_011_val_loss_4.580.h5\n",
      "196/196 [==============================] - 54s 273ms/step - loss: 4.6068 - val_loss: 4.5804\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5962\n",
      "Epoch 00012: val_loss did not improve from 4.58040\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.5910 - val_loss: 4.6619\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5831\n",
      "Epoch 00013: val_loss did not improve from 4.58040\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.5823 - val_loss: 4.5824\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5504\n",
      "Epoch 00014: val_loss did not improve from 4.58040\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.5516 - val_loss: 4.5852\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5746\n",
      "Epoch 00015: val_loss improved from 4.58040 to 4.56235, saving model to ./storage/precip_rnn/model16/epoch_015_val_loss_4.562.h5\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.5755 - val_loss: 4.5624\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5413\n",
      "Epoch 00016: val_loss did not improve from 4.56235\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.5388 - val_loss: 4.5691\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5672\n",
      "Epoch 00017: val_loss improved from 4.56235 to 4.55886, saving model to ./storage/precip_rnn/model16/epoch_017_val_loss_4.559.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 4.5631 - val_loss: 4.5589\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5297\n",
      "Epoch 00018: val_loss improved from 4.55886 to 4.55771, saving model to ./storage/precip_rnn/model16/epoch_018_val_loss_4.558.h5\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 4.5290 - val_loss: 4.5577\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5229\n",
      "Epoch 00019: val_loss did not improve from 4.55771\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 4.5232 - val_loss: 4.5673\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5303\n",
      "Epoch 00020: val_loss improved from 4.55771 to 4.55721, saving model to ./storage/precip_rnn/model16/epoch_020_val_loss_4.557.h5\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 4.5322 - val_loss: 4.5572\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5365\n",
      "Epoch 00021: val_loss did not improve from 4.55721\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 4.5400 - val_loss: 4.5574\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5166\n",
      "Epoch 00022: val_loss did not improve from 4.55721\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.5157 - val_loss: 4.5579\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5248\n",
      "Epoch 00023: val_loss improved from 4.55721 to 4.55653, saving model to ./storage/precip_rnn/model16/epoch_023_val_loss_4.557.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.5276 - val_loss: 4.5565\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5343\n",
      "Epoch 00024: val_loss improved from 4.55653 to 4.55589, saving model to ./storage/precip_rnn/model16/epoch_024_val_loss_4.556.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.5334 - val_loss: 4.5559\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5059\n",
      "Epoch 00025: val_loss improved from 4.55589 to 4.55365, saving model to ./storage/precip_rnn/model16/epoch_025_val_loss_4.554.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 4.5083 - val_loss: 4.5537\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5324\n",
      "Epoch 00026: val_loss did not improve from 4.55365\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 4.5335 - val_loss: 4.5540\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5335\n",
      "Epoch 00027: val_loss did not improve from 4.55365\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.5278 - val_loss: 4.5550\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5353\n",
      "Epoch 00028: val_loss did not improve from 4.55365\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 4.5354 - val_loss: 4.5538\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5188\n",
      "Epoch 00029: val_loss did not improve from 4.55365\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 4.5190 - val_loss: 4.5538\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5274\n",
      "Epoch 00030: val_loss did not improve from 4.55365\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.5241 - val_loss: 4.5538\n",
      "........ Training model 17 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 9.5884\n",
      "Epoch 00001: val_loss improved from inf to 10.58647, saving model to ./storage/precip_rnn/model17/epoch_001_val_loss_10.586.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 9.5858 - val_loss: 10.5865\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.4985\n",
      "Epoch 00002: val_loss improved from 10.58647 to 5.93971, saving model to ./storage/precip_rnn/model17/epoch_002_val_loss_5.940.h5\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 6.4893 - val_loss: 5.9397\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.9167\n",
      "Epoch 00003: val_loss improved from 5.93971 to 4.71230, saving model to ./storage/precip_rnn/model17/epoch_003_val_loss_4.712.h5\n",
      "196/196 [==============================] - 59s 299ms/step - loss: 4.9133 - val_loss: 4.7123\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.6584\n",
      "Epoch 00004: val_loss improved from 4.71230 to 4.66406, saving model to ./storage/precip_rnn/model17/epoch_004_val_loss_4.664.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 4.6575 - val_loss: 4.6641\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.4990\n",
      "Epoch 00005: val_loss improved from 4.66406 to 4.41058, saving model to ./storage/precip_rnn/model17/epoch_005_val_loss_4.411.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 4.5049 - val_loss: 4.4106\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.4302\n",
      "Epoch 00006: val_loss improved from 4.41058 to 4.24508, saving model to ./storage/precip_rnn/model17/epoch_006_val_loss_4.245.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.4332 - val_loss: 4.2451\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.3818\n",
      "Epoch 00007: val_loss did not improve from 4.24508\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.3804 - val_loss: 4.2700\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2570\n",
      "Epoch 00008: val_loss improved from 4.24508 to 4.11996, saving model to ./storage/precip_rnn/model17/epoch_008_val_loss_4.120.h5\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 4.2543 - val_loss: 4.1200\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1899\n",
      "Epoch 00009: val_loss did not improve from 4.11996\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 4.1884 - val_loss: 4.2137\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1030\n",
      "Epoch 00010: val_loss improved from 4.11996 to 4.05720, saving model to ./storage/precip_rnn/model17/epoch_010_val_loss_4.057.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 4.1034 - val_loss: 4.0572\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.0876\n",
      "Epoch 00011: val_loss improved from 4.05720 to 4.05614, saving model to ./storage/precip_rnn/model17/epoch_011_val_loss_4.056.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.0901 - val_loss: 4.0561\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.0937\n",
      "Epoch 00012: val_loss did not improve from 4.05614\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 4.0911 - val_loss: 4.1307\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.0090\n",
      "Epoch 00013: val_loss improved from 4.05614 to 3.99557, saving model to ./storage/precip_rnn/model17/epoch_013_val_loss_3.996.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 4.0082 - val_loss: 3.9956\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.0160\n",
      "Epoch 00014: val_loss improved from 3.99557 to 3.98753, saving model to ./storage/precip_rnn/model17/epoch_014_val_loss_3.988.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 4.0130 - val_loss: 3.9875\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9868\n",
      "Epoch 00015: val_loss did not improve from 3.98753\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 58s 298ms/step - loss: 3.9827 - val_loss: 3.9974\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9962\n",
      "Epoch 00016: val_loss did not improve from 3.98753\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 3.9967 - val_loss: 3.9911\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9635\n",
      "Epoch 00017: val_loss improved from 3.98753 to 3.97585, saving model to ./storage/precip_rnn/model17/epoch_017_val_loss_3.976.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.9653 - val_loss: 3.9758\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9602\n",
      "Epoch 00018: val_loss did not improve from 3.97585\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 3.9558 - val_loss: 3.9882\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9599\n",
      "Epoch 00019: val_loss did not improve from 3.97585\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 3.9600 - val_loss: 3.9881\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9315\n",
      "Epoch 00020: val_loss did not improve from 3.97585\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 3.9316 - val_loss: 3.9797\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9419\n",
      "Epoch 00021: val_loss did not improve from 3.97585\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 3.9401 - val_loss: 3.9792\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9537\n",
      "Epoch 00022: val_loss did not improve from 3.97585\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 3.9507 - val_loss: 3.9791\n",
      "........ Training model 18 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.5632\n",
      "Epoch 00001: val_loss improved from inf to 8.06698, saving model to ./storage/precip_rnn/model18/epoch_001_val_loss_8.067.h5\n",
      "196/196 [==============================] - 58s 293ms/step - loss: 7.5546 - val_loss: 8.0670\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.1354\n",
      "Epoch 00002: val_loss improved from 8.06698 to 5.37177, saving model to ./storage/precip_rnn/model18/epoch_002_val_loss_5.372.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 5.1309 - val_loss: 5.3718\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1884\n",
      "Epoch 00003: val_loss improved from 5.37177 to 4.11038, saving model to ./storage/precip_rnn/model18/epoch_003_val_loss_4.110.h5\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 4.1910 - val_loss: 4.1104\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9678\n",
      "Epoch 00004: val_loss improved from 4.11038 to 4.06018, saving model to ./storage/precip_rnn/model18/epoch_004_val_loss_4.060.h5\n",
      "196/196 [==============================] - 60s 307ms/step - loss: 3.9684 - val_loss: 4.0602\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8845\n",
      "Epoch 00005: val_loss improved from 4.06018 to 3.98207, saving model to ./storage/precip_rnn/model18/epoch_005_val_loss_3.982.h5\n",
      "196/196 [==============================] - 60s 304ms/step - loss: 3.8876 - val_loss: 3.9821\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8044\n",
      "Epoch 00006: val_loss improved from 3.98207 to 3.74128, saving model to ./storage/precip_rnn/model18/epoch_006_val_loss_3.741.h5\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 3.8088 - val_loss: 3.7413\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.7488\n",
      "Epoch 00007: val_loss did not improve from 3.74128\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 3.7483 - val_loss: 3.8435\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6785\n",
      "Epoch 00008: val_loss improved from 3.74128 to 3.61772, saving model to ./storage/precip_rnn/model18/epoch_008_val_loss_3.618.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 3.6787 - val_loss: 3.6177\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6233\n",
      "Epoch 00009: val_loss did not improve from 3.61772\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 3.6184 - val_loss: 3.6388\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5546\n",
      "Epoch 00010: val_loss improved from 3.61772 to 3.54555, saving model to ./storage/precip_rnn/model18/epoch_010_val_loss_3.546.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 3.5561 - val_loss: 3.5455\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5504\n",
      "Epoch 00011: val_loss improved from 3.54555 to 3.53345, saving model to ./storage/precip_rnn/model18/epoch_011_val_loss_3.533.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 3.5475 - val_loss: 3.5334\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5020\n",
      "Epoch 00012: val_loss did not improve from 3.53345\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 3.5040 - val_loss: 3.5475\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4786\n",
      "Epoch 00013: val_loss improved from 3.53345 to 3.53024, saving model to ./storage/precip_rnn/model18/epoch_013_val_loss_3.530.h5\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 3.4773 - val_loss: 3.5302\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4726\n",
      "Epoch 00014: val_loss did not improve from 3.53024\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 3.4726 - val_loss: 3.5339\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4444\n",
      "Epoch 00015: val_loss improved from 3.53024 to 3.51302, saving model to ./storage/precip_rnn/model18/epoch_015_val_loss_3.513.h5\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 3.4447 - val_loss: 3.5130\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4434\n",
      "Epoch 00016: val_loss did not improve from 3.51302\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 3.4445 - val_loss: 3.5447\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4220\n",
      "Epoch 00017: val_loss improved from 3.51302 to 3.50477, saving model to ./storage/precip_rnn/model18/epoch_017_val_loss_3.505.h5\n",
      "196/196 [==============================] - 59s 299ms/step - loss: 3.4200 - val_loss: 3.5048\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4256\n",
      "Epoch 00018: val_loss improved from 3.50477 to 3.50000, saving model to ./storage/precip_rnn/model18/epoch_018_val_loss_3.500.h5\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 3.4281 - val_loss: 3.5000\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4162\n",
      "Epoch 00019: val_loss did not improve from 3.50000\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 3.4179 - val_loss: 3.5023\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4120\n",
      "Epoch 00020: val_loss improved from 3.50000 to 3.49991, saving model to ./storage/precip_rnn/model18/epoch_020_val_loss_3.500.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 3.4131 - val_loss: 3.4999\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4217\n",
      "Epoch 00021: val_loss improved from 3.49991 to 3.49956, saving model to ./storage/precip_rnn/model18/epoch_021_val_loss_3.500.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.4171 - val_loss: 3.4996\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4148\n",
      "Epoch 00022: val_loss improved from 3.49956 to 3.49956, saving model to ./storage/precip_rnn/model18/epoch_022_val_loss_3.500.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.4130 - val_loss: 3.4996\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4060\n",
      "Epoch 00023: val_loss did not improve from 3.49956\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 3.4052 - val_loss: 3.5001\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4065\n",
      "Epoch 00024: val_loss improved from 3.49956 to 3.49870, saving model to ./storage/precip_rnn/model18/epoch_024_val_loss_3.499.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 3.4066 - val_loss: 3.4987\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4060\n",
      "Epoch 00025: val_loss did not improve from 3.49870\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 3.4103 - val_loss: 3.4991\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4030\n",
      "Epoch 00026: val_loss improved from 3.49870 to 3.49765, saving model to ./storage/precip_rnn/model18/epoch_026_val_loss_3.498.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 3.4013 - val_loss: 3.4976\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4215\n",
      "Epoch 00027: val_loss did not improve from 3.49765\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 3.4191 - val_loss: 3.4983\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.3994\n",
      "Epoch 00028: val_loss did not improve from 3.49765\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 58s 293ms/step - loss: 3.4036 - val_loss: 3.4981\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4000\n",
      "Epoch 00029: val_loss improved from 3.49765 to 3.49599, saving model to ./storage/precip_rnn/model18/epoch_029_val_loss_3.496.h5\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 3.4024 - val_loss: 3.4960\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4118\n",
      "Epoch 00030: val_loss did not improve from 3.49599\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 3.4077 - val_loss: 3.4963\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4081\n",
      "Epoch 00031: val_loss did not improve from 3.49599\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 3.4082 - val_loss: 3.4960\n",
      "Epoch 32/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4082\n",
      "Epoch 00032: val_loss did not improve from 3.49599\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 3.4080 - val_loss: 3.4979\n",
      "Epoch 33/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4237\n",
      "Epoch 00033: val_loss did not improve from 3.49599\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 3.4226 - val_loss: 3.4983\n",
      "Epoch 34/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4008\n",
      "Epoch 00034: val_loss did not improve from 3.49599\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 3.4021 - val_loss: 3.4982\n",
      "........ Training model 19 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8155\n",
      "Epoch 00001: val_loss improved from inf to 8.96266, saving model to ./storage/precip_rnn/model19/epoch_001_val_loss_8.963.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 5.8051 - val_loss: 8.9627\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.0765\n",
      "Epoch 00002: val_loss improved from 8.96266 to 4.29374, saving model to ./storage/precip_rnn/model19/epoch_002_val_loss_4.294.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 4.0803 - val_loss: 4.2937\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6575\n",
      "Epoch 00003: val_loss improved from 4.29374 to 3.42850, saving model to ./storage/precip_rnn/model19/epoch_003_val_loss_3.428.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 3.6555 - val_loss: 3.4285\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5281\n",
      "Epoch 00004: val_loss improved from 3.42850 to 3.31867, saving model to ./storage/precip_rnn/model19/epoch_004_val_loss_3.319.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.5315 - val_loss: 3.3187\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.4530\n",
      "Epoch 00005: val_loss improved from 3.31867 to 3.27123, saving model to ./storage/precip_rnn/model19/epoch_005_val_loss_3.271.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 3.4530 - val_loss: 3.2712\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.3685\n",
      "Epoch 00006: val_loss did not improve from 3.27123\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 3.3685 - val_loss: 3.4961\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.2863\n",
      "Epoch 00007: val_loss improved from 3.27123 to 3.21123, saving model to ./storage/precip_rnn/model19/epoch_007_val_loss_3.211.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 3.2841 - val_loss: 3.2112\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.2236\n",
      "Epoch 00008: val_loss did not improve from 3.21123\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 3.2201 - val_loss: 3.2724\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.1653\n",
      "Epoch 00009: val_loss improved from 3.21123 to 3.15245, saving model to ./storage/precip_rnn/model19/epoch_009_val_loss_3.152.h5\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 3.1659 - val_loss: 3.1524\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.1364\n",
      "Epoch 00010: val_loss improved from 3.15245 to 3.14057, saving model to ./storage/precip_rnn/model19/epoch_010_val_loss_3.141.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 3.1397 - val_loss: 3.1406\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.1064\n",
      "Epoch 00011: val_loss improved from 3.14057 to 3.12706, saving model to ./storage/precip_rnn/model19/epoch_011_val_loss_3.127.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 3.1085 - val_loss: 3.1271\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.0837\n",
      "Epoch 00012: val_loss improved from 3.12706 to 3.11053, saving model to ./storage/precip_rnn/model19/epoch_012_val_loss_3.111.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.0891 - val_loss: 3.1105\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.0822\n",
      "Epoch 00013: val_loss improved from 3.11053 to 3.08690, saving model to ./storage/precip_rnn/model19/epoch_013_val_loss_3.087.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.0798 - val_loss: 3.0869\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.0559\n",
      "Epoch 00014: val_loss did not improve from 3.08690\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 3.0559 - val_loss: 3.1093\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.0233\n",
      "Epoch 00015: val_loss improved from 3.08690 to 3.07865, saving model to ./storage/precip_rnn/model19/epoch_015_val_loss_3.079.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 3.0229 - val_loss: 3.0787\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.0041\n",
      "Epoch 00016: val_loss did not improve from 3.07865\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.0069 - val_loss: 3.0994\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9859\n",
      "Epoch 00017: val_loss improved from 3.07865 to 3.07295, saving model to ./storage/precip_rnn/model19/epoch_017_val_loss_3.073.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 2.9965 - val_loss: 3.0729\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9831\n",
      "Epoch 00018: val_loss improved from 3.07295 to 3.06904, saving model to ./storage/precip_rnn/model19/epoch_018_val_loss_3.069.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 2.9810 - val_loss: 3.0690\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9858\n",
      "Epoch 00019: val_loss did not improve from 3.06904\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 2.9843 - val_loss: 3.0745\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9689\n",
      "Epoch 00020: val_loss did not improve from 3.06904\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 2.9677 - val_loss: 3.0709\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9826\n",
      "Epoch 00021: val_loss did not improve from 3.06904\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 2.9813 - val_loss: 3.0716\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9648\n",
      "Epoch 00022: val_loss improved from 3.06904 to 3.06779, saving model to ./storage/precip_rnn/model19/epoch_022_val_loss_3.068.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 2.9613 - val_loss: 3.0678\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9531\n",
      "Epoch 00023: val_loss improved from 3.06779 to 3.06521, saving model to ./storage/precip_rnn/model19/epoch_023_val_loss_3.065.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 2.9536 - val_loss: 3.0652\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9543\n",
      "Epoch 00024: val_loss improved from 3.06521 to 3.06500, saving model to ./storage/precip_rnn/model19/epoch_024_val_loss_3.065.h5\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 2.9602 - val_loss: 3.0650\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9592\n",
      "Epoch 00025: val_loss did not improve from 3.06500\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 2.9627 - val_loss: 3.0676\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9594\n",
      "Epoch 00026: val_loss did not improve from 3.06500\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 2.9586 - val_loss: 3.0668\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9520\n",
      "Epoch 00027: val_loss did not improve from 3.06500\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 67s 342ms/step - loss: 2.9540 - val_loss: 3.0672\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9548\n",
      "Epoch 00028: val_loss did not improve from 3.06500\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 2.9527 - val_loss: 3.0664\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 2.9555\n",
      "Epoch 00029: val_loss did not improve from 3.06500\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 2.9586 - val_loss: 3.0665\n",
      "........ Training model 20 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.5839\n",
      "Epoch 00001: val_loss improved from inf to 0.75240, saving model to ./storage/precip_rnn/model20/epoch_001_val_loss_0.752.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 0.5829 - val_loss: 0.7524\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.4131\n",
      "Epoch 00002: val_loss improved from 0.75240 to 0.56824, saving model to ./storage/precip_rnn/model20/epoch_002_val_loss_0.568.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.4130 - val_loss: 0.5682\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3924\n",
      "Epoch 00003: val_loss improved from 0.56824 to 0.42448, saving model to ./storage/precip_rnn/model20/epoch_003_val_loss_0.424.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 0.3920 - val_loss: 0.4245\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3814\n",
      "Epoch 00004: val_loss improved from 0.42448 to 0.40735, saving model to ./storage/precip_rnn/model20/epoch_004_val_loss_0.407.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 0.3817 - val_loss: 0.4074\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3738\n",
      "Epoch 00005: val_loss improved from 0.40735 to 0.36988, saving model to ./storage/precip_rnn/model20/epoch_005_val_loss_0.370.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 0.3737 - val_loss: 0.3699\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3703\n",
      "Epoch 00006: val_loss improved from 0.36988 to 0.36609, saving model to ./storage/precip_rnn/model20/epoch_006_val_loss_0.366.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 0.3705 - val_loss: 0.3661\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3680\n",
      "Epoch 00007: val_loss did not improve from 0.36609\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 0.3681 - val_loss: 0.3670\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3573\n",
      "Epoch 00008: val_loss improved from 0.36609 to 0.36414, saving model to ./storage/precip_rnn/model20/epoch_008_val_loss_0.364.h5\n",
      "196/196 [==============================] - 53s 272ms/step - loss: 0.3576 - val_loss: 0.3641\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3549\n",
      "Epoch 00009: val_loss improved from 0.36414 to 0.36327, saving model to ./storage/precip_rnn/model20/epoch_009_val_loss_0.363.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 0.3547 - val_loss: 0.3633\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3522\n",
      "Epoch 00010: val_loss improved from 0.36327 to 0.36178, saving model to ./storage/precip_rnn/model20/epoch_010_val_loss_0.362.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.3516 - val_loss: 0.3618\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3503\n",
      "Epoch 00011: val_loss did not improve from 0.36178\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.3503 - val_loss: 0.3628\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3452\n",
      "Epoch 00012: val_loss improved from 0.36178 to 0.36122, saving model to ./storage/precip_rnn/model20/epoch_012_val_loss_0.361.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.3447 - val_loss: 0.3612\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3438\n",
      "Epoch 00013: val_loss improved from 0.36122 to 0.35994, saving model to ./storage/precip_rnn/model20/epoch_013_val_loss_0.360.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 0.3439 - val_loss: 0.3599\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3425\n",
      "Epoch 00014: val_loss did not improve from 0.35994\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 0.3425 - val_loss: 0.3604\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3394\n",
      "Epoch 00015: val_loss improved from 0.35994 to 0.35942, saving model to ./storage/precip_rnn/model20/epoch_015_val_loss_0.359.h5\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 0.3395 - val_loss: 0.3594\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3394\n",
      "Epoch 00016: val_loss did not improve from 0.35942\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 0.3391 - val_loss: 0.3599\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3379\n",
      "Epoch 00017: val_loss did not improve from 0.35942\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 0.3373 - val_loss: 0.3604\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3366\n",
      "Epoch 00018: val_loss did not improve from 0.35942\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.3367 - val_loss: 0.3595\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3364\n",
      "Epoch 00019: val_loss did not improve from 0.35942\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 273ms/step - loss: 0.3358 - val_loss: 0.3594\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3357\n",
      "Epoch 00020: val_loss improved from 0.35942 to 0.35939, saving model to ./storage/precip_rnn/model20/epoch_020_val_loss_0.359.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 0.3361 - val_loss: 0.3594\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3348\n",
      "Epoch 00021: val_loss did not improve from 0.35939\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 59s 303ms/step - loss: 0.3351 - val_loss: 0.3594\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3344\n",
      "Epoch 00022: val_loss improved from 0.35939 to 0.35936, saving model to ./storage/precip_rnn/model20/epoch_022_val_loss_0.359.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 0.3353 - val_loss: 0.3594\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3357\n",
      "Epoch 00023: val_loss improved from 0.35936 to 0.35928, saving model to ./storage/precip_rnn/model20/epoch_023_val_loss_0.359.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.3356 - val_loss: 0.3593\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3340\n",
      "Epoch 00024: val_loss did not improve from 0.35928\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 54s 273ms/step - loss: 0.3345 - val_loss: 0.3593\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3355\n",
      "Epoch 00025: val_loss improved from 0.35928 to 0.35922, saving model to ./storage/precip_rnn/model20/epoch_025_val_loss_0.359.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.3356 - val_loss: 0.3592\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3351\n",
      "Epoch 00026: val_loss did not improve from 0.35922\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 0.3353 - val_loss: 0.3594\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3360\n",
      "Epoch 00027: val_loss did not improve from 0.35922\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 0.3357 - val_loss: 0.3593\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3358\n",
      "Epoch 00028: val_loss did not improve from 0.35922\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 0.3357 - val_loss: 0.3594\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3346\n",
      "Epoch 00029: val_loss did not improve from 0.35922\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 0.3347 - val_loss: 0.3594\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 0.3358\n",
      "Epoch 00030: val_loss did not improve from 0.35922\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 0.3355 - val_loss: 0.3594\n",
      "........ Training model 21 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 8.9928\n",
      "Epoch 00001: val_loss improved from inf to 9.64201, saving model to ./storage/precip_rnn/model21/epoch_001_val_loss_9.642.h5\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 8.9814 - val_loss: 9.6420\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.0252\n",
      "Epoch 00002: val_loss improved from 9.64201 to 5.43478, saving model to ./storage/precip_rnn/model21/epoch_002_val_loss_5.435.h5\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 6.0191 - val_loss: 5.4348\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.5232\n",
      "Epoch 00003: val_loss improved from 5.43478 to 4.17364, saving model to ./storage/precip_rnn/model21/epoch_003_val_loss_4.174.h5\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 4.5211 - val_loss: 4.1736\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.2983\n",
      "Epoch 00004: val_loss improved from 4.17364 to 4.00671, saving model to ./storage/precip_rnn/model21/epoch_004_val_loss_4.007.h5\n",
      "196/196 [==============================] - 57s 289ms/step - loss: 4.2954 - val_loss: 4.0067\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.1598\n",
      "Epoch 00005: val_loss improved from 4.00671 to 3.90063, saving model to ./storage/precip_rnn/model21/epoch_005_val_loss_3.901.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 4.1583 - val_loss: 3.9006\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 4.0752\n",
      "Epoch 00006: val_loss did not improve from 3.90063\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 4.0708 - val_loss: 4.1753\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.9541\n",
      "Epoch 00007: val_loss improved from 3.90063 to 3.77698, saving model to ./storage/precip_rnn/model21/epoch_007_val_loss_3.777.h5\n",
      "196/196 [==============================] - 54s 274ms/step - loss: 3.9567 - val_loss: 3.7770\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8831\n",
      "Epoch 00008: val_loss improved from 3.77698 to 3.70433, saving model to ./storage/precip_rnn/model21/epoch_008_val_loss_3.704.h5\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 3.8841 - val_loss: 3.7043\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.8513\n",
      "Epoch 00009: val_loss did not improve from 3.70433\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 3.8490 - val_loss: 3.7864\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.7623\n",
      "Epoch 00010: val_loss improved from 3.70433 to 3.69006, saving model to ./storage/precip_rnn/model21/epoch_010_val_loss_3.690.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 3.7649 - val_loss: 3.6901\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.7516\n",
      "Epoch 00011: val_loss improved from 3.69006 to 3.63446, saving model to ./storage/precip_rnn/model21/epoch_011_val_loss_3.634.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 3.7511 - val_loss: 3.6345\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.7127\n",
      "Epoch 00012: val_loss did not improve from 3.63446\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 3.7137 - val_loss: 3.6501\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6621\n",
      "Epoch 00013: val_loss did not improve from 3.63446\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 3.6609 - val_loss: 3.6348\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6368\n",
      "Epoch 00014: val_loss improved from 3.63446 to 3.62233, saving model to ./storage/precip_rnn/model21/epoch_014_val_loss_3.622.h5\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 3.6352 - val_loss: 3.6223\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6374\n",
      "Epoch 00015: val_loss did not improve from 3.62233\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 3.6345 - val_loss: 3.6477\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6283\n",
      "Epoch 00016: val_loss did not improve from 3.62233\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 3.6269 - val_loss: 3.6275\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6163\n",
      "Epoch 00017: val_loss improved from 3.62233 to 3.62095, saving model to ./storage/precip_rnn/model21/epoch_017_val_loss_3.621.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 3.6193 - val_loss: 3.6210\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6163\n",
      "Epoch 00018: val_loss improved from 3.62095 to 3.61902, saving model to ./storage/precip_rnn/model21/epoch_018_val_loss_3.619.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 3.6155 - val_loss: 3.6190\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5963\n",
      "Epoch 00019: val_loss improved from 3.61902 to 3.61868, saving model to ./storage/precip_rnn/model21/epoch_019_val_loss_3.619.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 3.6021 - val_loss: 3.6187\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6122\n",
      "Epoch 00020: val_loss did not improve from 3.61868\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 3.6098 - val_loss: 3.6196\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6019\n",
      "Epoch 00021: val_loss improved from 3.61868 to 3.61823, saving model to ./storage/precip_rnn/model21/epoch_021_val_loss_3.618.h5\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 3.6112 - val_loss: 3.6182\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5928\n",
      "Epoch 00022: val_loss improved from 3.61823 to 3.61799, saving model to ./storage/precip_rnn/model21/epoch_022_val_loss_3.618.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 3.5931 - val_loss: 3.6180\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6052\n",
      "Epoch 00023: val_loss did not improve from 3.61799\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 3.6088 - val_loss: 3.6198\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6030\n",
      "Epoch 00024: val_loss improved from 3.61799 to 3.61633, saving model to ./storage/precip_rnn/model21/epoch_024_val_loss_3.616.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 3.6044 - val_loss: 3.6163\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5994\n",
      "Epoch 00025: val_loss improved from 3.61633 to 3.61602, saving model to ./storage/precip_rnn/model21/epoch_025_val_loss_3.616.h5\n",
      "196/196 [==============================] - 55s 278ms/step - loss: 3.5972 - val_loss: 3.6160\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6051\n",
      "Epoch 00026: val_loss did not improve from 3.61602\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 3.6044 - val_loss: 3.6189\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5932\n",
      "Epoch 00027: val_loss did not improve from 3.61602\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 58s 297ms/step - loss: 3.5932 - val_loss: 3.6186\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5893\n",
      "Epoch 00028: val_loss did not improve from 3.61602\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 3.5913 - val_loss: 3.6180\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6014\n",
      "Epoch 00029: val_loss improved from 3.61602 to 3.61368, saving model to ./storage/precip_rnn/model21/epoch_029_val_loss_3.614.h5\n",
      "196/196 [==============================] - 57s 291ms/step - loss: 3.5991 - val_loss: 3.6137\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5979\n",
      "Epoch 00030: val_loss did not improve from 3.61368\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 56s 283ms/step - loss: 3.5953 - val_loss: 3.6149\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.5994\n",
      "Epoch 00031: val_loss did not improve from 3.61368\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 3.5978 - val_loss: 3.6183\n",
      "Epoch 32/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6144\n",
      "Epoch 00032: val_loss did not improve from 3.61368\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 3.6147 - val_loss: 3.6178\n",
      "Epoch 33/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6034\n",
      "Epoch 00033: val_loss did not improve from 3.61368\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 3.6039 - val_loss: 3.6158\n",
      "Epoch 34/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 3.6068\n",
      "Epoch 00034: val_loss did not improve from 3.61368\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 3.6070 - val_loss: 3.6156\n",
      "........ Training model 22 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 12.8913\n",
      "Epoch 00001: val_loss improved from inf to 12.75258, saving model to ./storage/precip_rnn/model22/epoch_001_val_loss_12.753.h5\n",
      "196/196 [==============================] - 56s 284ms/step - loss: 12.8712 - val_loss: 12.7526\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 9.0597\n",
      "Epoch 00002: val_loss improved from 12.75258 to 8.39661, saving model to ./storage/precip_rnn/model22/epoch_002_val_loss_8.397.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 9.0497 - val_loss: 8.3966\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.5558\n",
      "Epoch 00003: val_loss improved from 8.39661 to 7.15390, saving model to ./storage/precip_rnn/model22/epoch_003_val_loss_7.154.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 6.5571 - val_loss: 7.1539\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.1066\n",
      "Epoch 00004: val_loss improved from 7.15390 to 5.81566, saving model to ./storage/precip_rnn/model22/epoch_004_val_loss_5.816.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 6.1040 - val_loss: 5.8157\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.9615\n",
      "Epoch 00005: val_loss improved from 5.81566 to 5.77347, saving model to ./storage/precip_rnn/model22/epoch_005_val_loss_5.773.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.9647 - val_loss: 5.7735\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8228\n",
      "Epoch 00006: val_loss improved from 5.77347 to 5.73244, saving model to ./storage/precip_rnn/model22/epoch_006_val_loss_5.732.h5\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 5.8232 - val_loss: 5.7324\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7743\n",
      "Epoch 00007: val_loss did not improve from 5.73244\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 58s 298ms/step - loss: 5.7774 - val_loss: 5.8780\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.6063\n",
      "Epoch 00008: val_loss improved from 5.73244 to 5.38024, saving model to ./storage/precip_rnn/model22/epoch_008_val_loss_5.380.h5\n",
      "196/196 [==============================] - 61s 313ms/step - loss: 5.6038 - val_loss: 5.3802\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.5597\n",
      "Epoch 00009: val_loss did not improve from 5.38024\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 59s 304ms/step - loss: 5.5552 - val_loss: 5.4939\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4462\n",
      "Epoch 00010: val_loss did not improve from 5.38024\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 5.4446 - val_loss: 5.4045\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3933\n",
      "Epoch 00011: val_loss improved from 5.38024 to 5.27046, saving model to ./storage/precip_rnn/model22/epoch_011_val_loss_5.270.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 5.3956 - val_loss: 5.2705\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.4091\n",
      "Epoch 00012: val_loss did not improve from 5.27046\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 5.4074 - val_loss: 5.2862\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3566\n",
      "Epoch 00013: val_loss improved from 5.27046 to 5.25587, saving model to ./storage/precip_rnn/model22/epoch_013_val_loss_5.256.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 5.3584 - val_loss: 5.2559\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3504\n",
      "Epoch 00014: val_loss did not improve from 5.25587\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.3550 - val_loss: 5.3084\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3616\n",
      "Epoch 00015: val_loss improved from 5.25587 to 5.25087, saving model to ./storage/precip_rnn/model22/epoch_015_val_loss_5.251.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 5.3584 - val_loss: 5.2509\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3271\n",
      "Epoch 00016: val_loss improved from 5.25087 to 5.24930, saving model to ./storage/precip_rnn/model22/epoch_016_val_loss_5.249.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.3234 - val_loss: 5.2493\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3133\n",
      "Epoch 00017: val_loss did not improve from 5.24930\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.3111 - val_loss: 5.2597\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3249\n",
      "Epoch 00018: val_loss improved from 5.24930 to 5.24518, saving model to ./storage/precip_rnn/model22/epoch_018_val_loss_5.245.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.3208 - val_loss: 5.2452\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3070\n",
      "Epoch 00019: val_loss did not improve from 5.24518\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 55s 282ms/step - loss: 5.3085 - val_loss: 5.2468\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2893\n",
      "Epoch 00020: val_loss improved from 5.24518 to 5.24334, saving model to ./storage/precip_rnn/model22/epoch_020_val_loss_5.243.h5\n",
      "196/196 [==============================] - 58s 296ms/step - loss: 5.2872 - val_loss: 5.2433\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2883\n",
      "Epoch 00021: val_loss did not improve from 5.24334\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 5.2884 - val_loss: 5.2481\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2967\n",
      "Epoch 00022: val_loss improved from 5.24334 to 5.24281, saving model to ./storage/precip_rnn/model22/epoch_022_val_loss_5.243.h5\n",
      "196/196 [==============================] - 56s 285ms/step - loss: 5.2971 - val_loss: 5.2428\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3100\n",
      "Epoch 00023: val_loss did not improve from 5.24281\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.3091 - val_loss: 5.2436\n",
      "Epoch 24/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3240\n",
      "Epoch 00024: val_loss did not improve from 5.24281\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 5.3199 - val_loss: 5.2437\n",
      "Epoch 25/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3217\n",
      "Epoch 00025: val_loss improved from 5.24281 to 5.24245, saving model to ./storage/precip_rnn/model22/epoch_025_val_loss_5.242.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 5.3244 - val_loss: 5.2425\n",
      "Epoch 26/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2991\n",
      "Epoch 00026: val_loss improved from 5.24245 to 5.24230, saving model to ./storage/precip_rnn/model22/epoch_026_val_loss_5.242.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.2972 - val_loss: 5.2423\n",
      "Epoch 27/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3044\n",
      "Epoch 00027: val_loss improved from 5.24230 to 5.24155, saving model to ./storage/precip_rnn/model22/epoch_027_val_loss_5.242.h5\n",
      "196/196 [==============================] - 54s 277ms/step - loss: 5.3051 - val_loss: 5.2416\n",
      "Epoch 28/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2880\n",
      "Epoch 00028: val_loss did not improve from 5.24155\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.2886 - val_loss: 5.2427\n",
      "Epoch 29/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2721\n",
      "Epoch 00029: val_loss improved from 5.24155 to 5.24036, saving model to ./storage/precip_rnn/model22/epoch_029_val_loss_5.240.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.2686 - val_loss: 5.2404\n",
      "Epoch 30/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3045\n",
      "Epoch 00030: val_loss did not improve from 5.24036\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 5.3100 - val_loss: 5.2423\n",
      "Epoch 31/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3033\n",
      "Epoch 00031: val_loss did not improve from 5.24036\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 5.3005 - val_loss: 5.2412\n",
      "Epoch 32/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2896\n",
      "Epoch 00032: val_loss improved from 5.24036 to 5.23797, saving model to ./storage/precip_rnn/model22/epoch_032_val_loss_5.238.h5\n",
      "196/196 [==============================] - 57s 292ms/step - loss: 5.2872 - val_loss: 5.2380\n",
      "Epoch 33/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3090\n",
      "Epoch 00033: val_loss did not improve from 5.23797\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "196/196 [==============================] - 57s 290ms/step - loss: 5.3136 - val_loss: 5.2399\n",
      "Epoch 34/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2979\n",
      "Epoch 00034: val_loss did not improve from 5.23797\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 5.2975 - val_loss: 5.2394\n",
      "Epoch 35/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.2797\n",
      "Epoch 00035: val_loss did not improve from 5.23797\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "196/196 [==============================] - 53s 273ms/step - loss: 5.2837 - val_loss: 5.2418\n",
      "Epoch 36/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3041\n",
      "Epoch 00036: val_loss did not improve from 5.23797\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.3058 - val_loss: 5.2390\n",
      "Epoch 37/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.3113\n",
      "Epoch 00037: val_loss did not improve from 5.23797\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "196/196 [==============================] - 59s 301ms/step - loss: 5.3082 - val_loss: 5.2409\n",
      "........ Training model 23 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 14.1379\n",
      "Epoch 00001: val_loss improved from inf to 13.85146, saving model to ./storage/precip_rnn/model23/epoch_001_val_loss_13.851.h5\n",
      "196/196 [==============================] - 57s 293ms/step - loss: 14.1294 - val_loss: 13.8515\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 10.1666\n",
      "Epoch 00002: val_loss improved from 13.85146 to 9.28785, saving model to ./storage/precip_rnn/model23/epoch_002_val_loss_9.288.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 10.1632 - val_loss: 9.2878\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.2983\n",
      "Epoch 00003: val_loss improved from 9.28785 to 6.97104, saving model to ./storage/precip_rnn/model23/epoch_003_val_loss_6.971.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 7.2940 - val_loss: 6.9710\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.6837\n",
      "Epoch 00004: val_loss improved from 6.97104 to 6.60494, saving model to ./storage/precip_rnn/model23/epoch_004_val_loss_6.605.h5\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 6.6830 - val_loss: 6.6049\n",
      "Epoch 5/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.4605\n",
      "Epoch 00005: val_loss improved from 6.60494 to 6.30149, saving model to ./storage/precip_rnn/model23/epoch_005_val_loss_6.301.h5\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 6.4581 - val_loss: 6.3015\n",
      "Epoch 6/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.3773\n",
      "Epoch 00006: val_loss improved from 6.30149 to 6.29263, saving model to ./storage/precip_rnn/model23/epoch_006_val_loss_6.293.h5\n",
      "196/196 [==============================] - 55s 281ms/step - loss: 6.3772 - val_loss: 6.2926\n",
      "Epoch 7/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.3069\n",
      "Epoch 00007: val_loss did not improve from 6.29263\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 6.3085 - val_loss: 6.4496\n",
      "Epoch 8/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.1119\n",
      "Epoch 00008: val_loss improved from 6.29263 to 6.01628, saving model to ./storage/precip_rnn/model23/epoch_008_val_loss_6.016.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 6.1184 - val_loss: 6.0163\n",
      "Epoch 9/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 6.0736\n",
      "Epoch 00009: val_loss did not improve from 6.01628\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 6.0762 - val_loss: 6.3918\n",
      "Epoch 10/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.9732\n",
      "Epoch 00010: val_loss did not improve from 6.01628\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "196/196 [==============================] - 56s 288ms/step - loss: 5.9730 - val_loss: 6.1155\n",
      "Epoch 11/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.9155\n",
      "Epoch 00011: val_loss improved from 6.01628 to 5.95944, saving model to ./storage/precip_rnn/model23/epoch_011_val_loss_5.959.h5\n",
      "196/196 [==============================] - 55s 280ms/step - loss: 5.9092 - val_loss: 5.9594\n",
      "Epoch 12/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.9036\n",
      "Epoch 00012: val_loss did not improve from 5.95944\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 5.9015 - val_loss: 5.9609\n",
      "Epoch 13/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8892\n",
      "Epoch 00013: val_loss improved from 5.95944 to 5.93229, saving model to ./storage/precip_rnn/model23/epoch_013_val_loss_5.932.h5\n",
      "196/196 [==============================] - 54s 275ms/step - loss: 5.8858 - val_loss: 5.9323\n",
      "Epoch 14/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8345\n",
      "Epoch 00014: val_loss improved from 5.93229 to 5.92263, saving model to ./storage/precip_rnn/model23/epoch_014_val_loss_5.923.h5\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 5.8367 - val_loss: 5.9226\n",
      "Epoch 15/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8370\n",
      "Epoch 00015: val_loss did not improve from 5.92263\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "196/196 [==============================] - 54s 278ms/step - loss: 5.8414 - val_loss: 5.9237\n",
      "Epoch 16/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8243\n",
      "Epoch 00016: val_loss improved from 5.92263 to 5.91545, saving model to ./storage/precip_rnn/model23/epoch_016_val_loss_5.915.h5\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.8244 - val_loss: 5.9154\n",
      "Epoch 17/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8342\n",
      "Epoch 00017: val_loss improved from 5.91545 to 5.91479, saving model to ./storage/precip_rnn/model23/epoch_017_val_loss_5.915.h5\n",
      "196/196 [==============================] - 56s 287ms/step - loss: 5.8289 - val_loss: 5.9148\n",
      "Epoch 18/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8248\n",
      "Epoch 00018: val_loss improved from 5.91479 to 5.90334, saving model to ./storage/precip_rnn/model23/epoch_018_val_loss_5.903.h5\n",
      "196/196 [==============================] - 56s 286ms/step - loss: 5.8242 - val_loss: 5.9033\n",
      "Epoch 19/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8163\n",
      "Epoch 00019: val_loss did not improve from 5.90334\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.8155 - val_loss: 5.9044\n",
      "Epoch 20/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.8124\n",
      "Epoch 00020: val_loss did not improve from 5.90334\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "196/196 [==============================] - 54s 276ms/step - loss: 5.8121 - val_loss: 5.9076\n",
      "Epoch 21/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7869\n",
      "Epoch 00021: val_loss did not improve from 5.90334\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "196/196 [==============================] - 55s 279ms/step - loss: 5.7832 - val_loss: 5.9083\n",
      "Epoch 22/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7978\n",
      "Epoch 00022: val_loss did not improve from 5.90334\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "196/196 [==============================] - 55s 283ms/step - loss: 5.7983 - val_loss: 5.9065\n",
      "Epoch 23/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 5.7738\n",
      "Epoch 00023: val_loss did not improve from 5.90334\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "196/196 [==============================] - 59s 300ms/step - loss: 5.7715 - val_loss: 5.9050\n",
      "........ Training model 24 ........\n",
      "Epoch 1/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 15.0814\n",
      "Epoch 00001: val_loss improved from inf to 14.14755, saving model to ./storage/precip_rnn/model24/epoch_001_val_loss_14.148.h5\n",
      "196/196 [==============================] - 60s 308ms/step - loss: 15.0719 - val_loss: 14.1476\n",
      "Epoch 2/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 11.0360\n",
      "Epoch 00002: val_loss improved from 14.14755 to 9.87966, saving model to ./storage/precip_rnn/model24/epoch_002_val_loss_9.880.h5\n",
      "196/196 [==============================] - 58s 294ms/step - loss: 11.0268 - val_loss: 9.8797\n",
      "Epoch 3/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.9300\n",
      "Epoch 00003: val_loss improved from 9.87966 to 7.29917, saving model to ./storage/precip_rnn/model24/epoch_003_val_loss_7.299.h5\n",
      "196/196 [==============================] - 58s 295ms/step - loss: 7.9267 - val_loss: 7.2992\n",
      "Epoch 4/100\n",
      "195/196 [============================>.] - ETA: 0s - loss: 7.3535"
     ]
    }
   ],
   "source": [
    "# due to time limitations, we will not do k-fold ensemble \n",
    "# fix the train and validation sets. \n",
    "train_files = [x for x in os.listdir('./storage/precipitation/train/')] \n",
    "train_files = shuffle(train_files)\n",
    "k = int(0.8 * len(train_files)) \n",
    "train_data = train_files[:k]\n",
    "val_data = train_files[k:]\n",
    "\n",
    "partition = {'train':[], 'validation':[]} \n",
    "\n",
    "for filename in train_data: \n",
    "    partition['train'].append(filename) \n",
    "for filename in val_data: \n",
    "    partition['validation'].append(filename)  \n",
    "\n",
    "# we need to train 36 different ConvLSTM models \n",
    "models = [] \n",
    "cnt = 1 \n",
    "for rIdx in range(10):  \n",
    "    for cIdx in range(10):\n",
    "        params_train_gen = {'dim': (120,120),\n",
    "                    'batch_size': 256,\n",
    "                    'n_channels': 4,\n",
    "                    'n_timesteps': 4,\n",
    "                    'shuffle': True,\n",
    "                    'augment_data': False,\n",
    "                    'rIdx': rIdx,\n",
    "                    'cIdx': cIdx}  \n",
    "\n",
    "        params_val_gen = {'dim': (120,120), \n",
    "                  'batch_size': 256, \n",
    "                  'n_channels': 4, \n",
    "                  'n_timesteps': 4,\n",
    "                  'shuffle': True,\n",
    "                  'augment_data': False,\n",
    "                  'rIdx': rIdx,\n",
    "                  'cIdx': cIdx} \n",
    "         \n",
    "        print(\"........ Training model {} ........\".format(cnt))\n",
    "        training_generator = DataGenerator(partition['train'], **params_train_gen)\n",
    "        validation_generator = DataGenerator(partition['validation'], **params_val_gen) \n",
    "        model = simple_rnn()\n",
    "        \n",
    "        os.mkdir('./storage/precip_rnn/model' + str(cnt) + '/')\n",
    "        model_path = './storage/precip_rnn/model' + str(cnt) + '/epoch_{epoch:03d}_val_loss_{val_loss:.3f}.h5'\n",
    "        learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 1, verbose = 1, factor = 0.5)\n",
    "        checkpoint = ModelCheckpoint(filepath = model_path, monitor = 'val_loss', verbose = 1, save_best_only = True)\n",
    "        early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5) \n",
    "        history = model.fit_generator(generator = training_generator, validation_data = validation_generator, epochs = 100, callbacks = [checkpoint, early_stopping, learning_rate_reduction])\n",
    "    \n",
    "        #print(\"........ Appending model {} ........\".format(cnt))\n",
    "        #models.append(model)\n",
    "        cnt += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
